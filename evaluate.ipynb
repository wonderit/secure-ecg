{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "from scipy import stats\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "# define model type ('cnnavg', 'cnnmax')\n",
    "MODEL_TYPE = 'cnnmax'\n",
    "MEAN = 61.9\n",
    "STD = 10.9\n",
    "BATCH_SIZE = 32\n",
    "PADDING = 'same'\n",
    "LOG_INTERVAL = 5\n",
    "EPOCHS = 3\n",
    "batches = 5000 // BATCH_SIZE\n",
    "if MODEL_TYPE == 'cnnavg_concat':\n",
    "    N_HIDDEN = 7\n",
    "else:\n",
    "    N_HIDDEN = 5\n",
    "model_description = '128int_max_adam_max30_lr01'\n",
    "CACHE_FOLDER = 'cache_{}'.format(model_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define functions\n",
    "def rescale(arr, m, s):\n",
    "    arr = arr * s\n",
    "    arr = arr + m\n",
    "    return arr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define models\n",
    "\n",
    "class CNNAVG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAVG, self).__init__()\n",
    "        self.kernel_size = 7\n",
    "        self.padding_size = 0\n",
    "        self.channel_size = 6\n",
    "        self.avgpool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.avgpool2 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.avgpool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        if PADDING == 'valid':\n",
    "            self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size, padding=self.padding_size)\n",
    "            self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                    padding=self.padding_size)\n",
    "            self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                    padding=self.padding_size)\n",
    "            self.fc1 = nn.Linear(342, 16)\n",
    "        else:\n",
    "\n",
    "            self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.fc1 = nn.Linear(372, 16)\n",
    "        self.fc2 = nn.Linear(16, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # 32\n",
    "        x = self.avgpool1(x)  # 32\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.avgpool2(x)\n",
    "        y = F.relu(self.conv3(x))\n",
    "        y = self.avgpool3(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.fc3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CNNMAX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNMAX, self).__init__()\n",
    "        self.kernel_size = 7\n",
    "        self.padding_size = 0\n",
    "        self.channel_size = 6\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        if PADDING == 'valid':\n",
    "            self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size, padding=self.padding_size)\n",
    "            self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding_size)\n",
    "            self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=self.padding_size)\n",
    "            self.fc1 = nn.Linear(342, 16)\n",
    "        else:\n",
    "\n",
    "            self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                                   padding=(self.kernel_size // 2))\n",
    "            self.fc1 = nn.Linear(372, 16)\n",
    "        self.fc2 = nn.Linear(16, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # 32\n",
    "        x = self.maxpool1(x)  # 32\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        y = F.relu(self.conv3(x))\n",
    "        y = self.maxpool3(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.fc3(y)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_model(model, epoch, batch, cache_folder):\n",
    "    wait_count = 0\n",
    "    if batch == 5:\n",
    "        batch = 10\n",
    "    file_name_check = '../data/results/{}/ecg_P1_{}_{}_W0.bin'.format(cache_folder, epoch, batch)\n",
    "\n",
    "    while not os.path.exists(file_name_check):\n",
    "        wait_count = wait_count + 1\n",
    "        if wait_count > 10:\n",
    "            print('exit process')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Waiting 60s for the file to be generated : ', file_name_check)\n",
    "            time.sleep(60)\n",
    "\n",
    "    W = [[] for _ in range(N_HIDDEN + 1)]\n",
    "    for l in range(N_HIDDEN + 1):\n",
    "        W[l] = np.loadtxt('../data/results/{}/ecg_P1_{}_{}_W{}.bin'.format(cache_folder, epoch, batch, l))\n",
    "\n",
    "    # Initialize bias vector with zeros.\n",
    "    b = [[] for _ in range(N_HIDDEN + 1)]\n",
    "    for l in range(N_HIDDEN + 1):\n",
    "        b[l] = np.loadtxt('../data/results/{}/ecg_P1_{}_{}_b{}.bin'.format(cache_folder, epoch, batch, l))\n",
    "\n",
    "\n",
    "    if MODEL_TYPE == 'cnnavg_concat':\n",
    "        W[0] = np.transpose(W[0])\n",
    "        w0_from_text = torch.from_numpy(W[0].reshape(6, 3, 7))\n",
    "        model.conv1.weight = torch.nn.Parameter(w0_from_text)\n",
    "        b0_from_text = torch.from_numpy(b[0])\n",
    "        model.conv1.bias = torch.nn.Parameter(b0_from_text)\n",
    "\n",
    "        W[1] = np.transpose(W[1])\n",
    "        w1_from_text = torch.from_numpy(W[1].reshape(6, 6, 7))\n",
    "        model.conv2.weight = torch.nn.Parameter(w1_from_text)\n",
    "        b1_from_text = torch.from_numpy(b[1])\n",
    "        model.conv2.bias = torch.nn.Parameter(b1_from_text)\n",
    "\n",
    "        W[2] = np.transpose(W[2])\n",
    "        w2_from_text = torch.from_numpy(W[2].reshape(6, 6, 7))\n",
    "        model.conv3.weight = torch.nn.Parameter(w2_from_text)\n",
    "        b2_from_text = torch.from_numpy(b[2])\n",
    "        model.conv3.bias = torch.nn.Parameter(b2_from_text)\n",
    "\n",
    "\n",
    "        W[3] = np.transpose(W[3])\n",
    "        w_from_text = torch.from_numpy(W[3].reshape(6, 12, 7))\n",
    "        model.conv4.weight = torch.nn.Parameter(w_from_text)\n",
    "        b_from_text = torch.from_numpy(b[3])\n",
    "        model.conv4.bias = torch.nn.Parameter(b_from_text)\n",
    "\n",
    "        W[4] = np.transpose(W[4])\n",
    "        w2_from_text = torch.from_numpy(W[4].reshape(4, 18, 7))\n",
    "        model.conv5.weight = torch.nn.Parameter(w2_from_text)\n",
    "        b2_from_text = torch.from_numpy(b[4])\n",
    "        model.conv5.bias = torch.nn.Parameter(b2_from_text)\n",
    "\n",
    "        W[5] = np.transpose(W[5])\n",
    "        w3_from_text = torch.from_numpy(W[5])\n",
    "        model.fc1.weight = torch.nn.Parameter(w3_from_text)\n",
    "        b3_from_text = torch.from_numpy(b[5])\n",
    "        model.fc1.bias = torch.nn.Parameter(b3_from_text)\n",
    "\n",
    "        W[6] = np.transpose(W[6])\n",
    "        w4_from_text = torch.from_numpy(W[6])\n",
    "        model.fc2.weight = torch.nn.Parameter(w4_from_text)\n",
    "        b4_from_text = torch.from_numpy(b[6])\n",
    "        model.fc2.bias = torch.nn.Parameter(b4_from_text)\n",
    "\n",
    "        w5_from_text = torch.from_numpy(W[7])\n",
    "        w5_from_text = w5_from_text.reshape(1, 64)\n",
    "        model.fc3.weight = torch.nn.Parameter(w5_from_text)\n",
    "        b5_from_text = torch.from_numpy(b[7])\n",
    "        model.fc3.bias = torch.nn.Parameter(b5_from_text)\n",
    "\n",
    "    else:\n",
    "        W[0] = np.transpose(W[0])\n",
    "        w0_from_text = torch.from_numpy(W[0].reshape(6, 3, 7))\n",
    "        model.conv1.weight = torch.nn.Parameter(w0_from_text)\n",
    "        b0_from_text = torch.from_numpy(b[0])\n",
    "        model.conv1.bias = torch.nn.Parameter(b0_from_text)\n",
    "\n",
    "        W[1] = np.transpose(W[1])\n",
    "        w1_from_text = torch.from_numpy(W[1].reshape(6, 6, 7))\n",
    "        model.conv2.weight = torch.nn.Parameter(w1_from_text)\n",
    "        b1_from_text = torch.from_numpy(b[1])\n",
    "        model.conv2.bias = torch.nn.Parameter(b1_from_text)\n",
    "\n",
    "        W[2] = np.transpose(W[2])\n",
    "        w2_from_text = torch.from_numpy(W[2].reshape(6, 6, 7))\n",
    "        model.conv3.weight = torch.nn.Parameter(w2_from_text)\n",
    "        b2_from_text = torch.from_numpy(b[2])\n",
    "        model.conv3.bias = torch.nn.Parameter(b2_from_text)\n",
    "\n",
    "        W[3] = np.transpose(W[3])\n",
    "        w3_from_text = torch.from_numpy(W[3])\n",
    "        model.fc1.weight = torch.nn.Parameter(w3_from_text)\n",
    "\n",
    "        b3_from_text = torch.from_numpy(b[3])\n",
    "        model.fc1.bias = torch.nn.Parameter(b3_from_text)\n",
    "\n",
    "        W[4] = np.transpose(W[4])\n",
    "        w4_from_text = torch.from_numpy(W[4])\n",
    "        model.fc2.weight = torch.nn.Parameter(w4_from_text)\n",
    "        b4_from_text = torch.from_numpy(b[4])\n",
    "        model.fc2.bias = torch.nn.Parameter(b4_from_text)\n",
    "\n",
    "        w5_from_text = torch.from_numpy(W[5])\n",
    "        w5_from_text = w5_from_text.reshape(1, 64)\n",
    "        model.fc3.weight = torch.nn.Parameter(w5_from_text)\n",
    "        b5_from_text = torch.from_numpy(b[5])\n",
    "        model.fc3.bias = torch.nn.Parameter(b5_from_text)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def report_scores(X, y, trained_model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # y_score = []\n",
    "\n",
    "    # DON'T NORMALIZE X\n",
    "    # X = scale(X, mean_x, std_x)\n",
    "    # print('Example : X - ', X[0, 0:3], 'y - ', y[0])\n",
    "\n",
    "    reshaped_X = X.reshape(X.shape[0], 3, 500)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = trained_model(torch.from_numpy(reshaped_X))\n",
    "        #\n",
    "        # output rescale\n",
    "        scores = rescale(scores, MEAN, STD)\n",
    "        y = rescale(y, MEAN, STD)\n",
    "\n",
    "        mse_loss = metrics.mean_squared_error(y, scores)\n",
    "\n",
    "        y_true.extend(list(y))\n",
    "        y_pred.extend(scores)\n",
    "\n",
    "    return y_true, y_pred, mse_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def r_mse(y_true, y_pred, mse):\n",
    "    r = stats.pearsonr(y_true, y_pred)[0]\n",
    "    # r2 = r ** 2\n",
    "\n",
    "    result_message = 'r:{:.3f}, mse:{:.3f}, std:{:.3f},{:.3f}'.format(r, mse, np.std(y_true), np.std(y_pred))\n",
    "    return result_message, r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.genfromtxt('../data/ecg/text_demo_5500/Xtrain', delimiter=',', dtype='float')\n",
    "y_train = np.genfromtxt('../data/ecg/text_demo_5500/ytrain', delimiter=',', dtype='float')\n",
    "\n",
    "X_test = np.genfromtxt('../data/ecg/text_demo_5500/Xtest', delimiter=',', dtype='float')\n",
    "y_test = np.genfromtxt('../data/ecg/text_demo_5500/ytest', delimiter=',', dtype='float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "result_path = 'result_{}'.format(CACHE_FOLDER)\n",
    "\n",
    "def scatter_plot(y_true, y_pred, message, epoch, batch):\n",
    "    result = np.column_stack((y_true,y_pred))\n",
    "\n",
    "    if not os.path.exists('{}/{}'.format(result_path, 'csv')):\n",
    "        os.makedirs('{}/{}'.format(result_path, 'csv'))\n",
    "\n",
    "    if not os.path.exists('{}/{}'.format(result_path, 'scatter')):\n",
    "        os.makedirs('{}/{}'.format(result_path, 'scatter'))\n",
    "\n",
    "    pd.DataFrame(result).to_csv(\"{}/csv/{}.csv\".format(result_path, epoch), index=False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    fig, ax = plt.subplots()\n",
    "    line = mlines.Line2D([0, 1], [0, 1], color='red')\n",
    "\n",
    "    ax.scatter(y_pred, y_true, s=3)\n",
    "\n",
    "    transform = ax.transAxes\n",
    "    line.set_transform(transform)\n",
    "    ax.add_line(line)\n",
    "\n",
    "    plt.suptitle(message)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    # set axes range\n",
    "    plt.xlim(30, 110)\n",
    "    plt.ylim(30, 110)\n",
    "\n",
    "    plt.savefig(\"{}/scatter/{}_{}.png\".format(result_path, epoch, batch), dpi=600)\n",
    "    plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "batch : 5\n",
      "batch : 6\n",
      "batch : 7\n",
      "batch : 8\n",
      "batch : 9\n",
      "batch : 10\n",
      "batch : 11\n",
      "batch : 12\n",
      "batch : 13\n",
      "batch : 14\n",
      "batch : 15\n",
      "batch : 16\n",
      "batch : 17\n",
      "batch : 18\n",
      "batch : 19\n",
      "batch : 20\n",
      "batch : 21\n",
      "batch : 22\n",
      "batch : 23\n",
      "batch : 24\n",
      "batch : 25\n",
      "batch : 26\n",
      "batch : 27\n",
      "batch : 28\n",
      "batch : 29\n",
      "batch : 30\n",
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "batch : 5\n",
      "batch : 6\n",
      "batch : 7\n",
      "batch : 8\n",
      "batch : 9\n",
      "batch : 10\n",
      "batch : 11\n",
      "batch : 12\n",
      "batch : 13\n",
      "batch : 14\n",
      "batch : 15\n",
      "batch : 16\n",
      "batch : 17\n",
      "batch : 18\n",
      "batch : 19\n",
      "batch : 20\n",
      "batch : 21\n",
      "batch : 22\n",
      "batch : 23\n",
      "batch : 24\n",
      "batch : 25\n",
      "batch : 26\n",
      "batch : 27\n",
      "batch : 28\n",
      "batch : 29\n",
      "batch : 30\n",
      "batch : 1\n",
      "batch : 2\n",
      "batch : 3\n",
      "batch : 4\n",
      "batch : 5\n",
      "batch : 6\n",
      "batch : 7\n",
      "batch : 8\n",
      "batch : 9\n",
      "batch : 10\n",
      "batch : 11\n",
      "batch : 12\n",
      "batch : 13\n",
      "batch : 14\n",
      "batch : 15\n",
      "batch : 16\n",
      "batch : 17\n",
      "batch : 18\n",
      "batch : 19\n",
      "batch : 20\n",
      "batch : 21\n",
      "batch : 22\n",
      "batch : 23\n",
      "batch : 24\n",
      "batch : 25\n",
      "batch : 26\n",
      "batch : 27\n",
      "batch : 28\n",
      "batch : 29\n",
      "batch : 30\n",
      "FINISH\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_array = []\n",
    "r2_train = []\n",
    "r2_test = []\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "log_batches = int(batches // LOG_INTERVAL)\n",
    "step = 0\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "\n",
    "    for i in range(log_batches):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        step = (log_batches * e + i)\n",
    "\n",
    "        if step > batches:\n",
    "            continue\n",
    "        if MODEL_TYPE == 'cnnavg':\n",
    "            model = CNNAVG()\n",
    "        elif MODEL_TYPE == 'cnnmax':\n",
    "            model = CNNMAX()\n",
    "        else:\n",
    "            model = CNNMAX()\n",
    "\n",
    "\n",
    "        model = load_model(model, e, i * LOG_INTERVAL, CACHE_FOLDER)\n",
    "\n",
    "        y_true_train, y_pred_train, train_mse_loss = report_scores(X_train, y_train, model)\n",
    "\n",
    "        print('batch : {}'.format(i))\n",
    "\n",
    "\n",
    "        # print('Training mse_loss: {0:.4f}'.format(train_mse_loss))\n",
    "\n",
    "        y_true, y_pred, test_mse_loss = report_scores(X_test, y_test, model)\n",
    "\n",
    "\n",
    "        _, train_r = r_mse(y_true_train, y_pred_train, train_mse_loss)\n",
    "\n",
    "\n",
    "        y_true = np.array(y_true, dtype=np.float)\n",
    "        y_true = y_true.flatten()\n",
    "        y_pred = np.array(y_pred, dtype=np.float)\n",
    "        y_pred = y_pred.flatten()\n",
    "        rm, test_r = r_mse(y_true, y_pred, test_mse_loss)\n",
    "\n",
    "        result = dict()\n",
    "        result['mse_train'] = train_mse_loss\n",
    "        result['mse_test'] = test_mse_loss\n",
    "        result['r_train'] = train_r\n",
    "        result['r_test'] = test_r\n",
    "        result_array.append(result)\n",
    "\n",
    "        if i == 30:\n",
    "            scatter_plot(y_true, y_pred, rm, e, i * LOG_INTERVAL)\n",
    "print('FINISH')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = \"result_{}.csv\".format(model_description)\n",
    "csv_columns = ['mse_train', 'mse_test', 'r_train', 'r_test']\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in result_array:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}