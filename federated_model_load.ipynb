{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \" \"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-c\", \"--is_comet\", help=\"Set is Comet\", action='store_true')\n",
    "parser.add_argument(\"-m\", \"--model_type\", help=\"model name(shallow, normal, ann, mpc, cnn2d)\", type=str, default='cnnmax')\n",
    "parser.add_argument(\"-mpc\", \"--mpc\", help=\"shallow model\", action='store_true')\n",
    "parser.add_argument(\"-lt\", \"--loss_type\", help=\"use sgd as optimizer\", type=str, default='sgd')\n",
    "parser.add_argument(\"-e\", \"--epochs\", help=\"Set epochs\", type=int, default=3)\n",
    "parser.add_argument(\"-es\", \"--epochs_saved\", help=\"Set epochs\", type=int, default=10)\n",
    "parser.add_argument(\"-b\", \"--batch_size\", help=\"Set batch size\", type=int, default=32)\n",
    "parser.add_argument(\"-lr\", \"--lr\", help=\"Set learning rate\", type=float, default=1e-2)\n",
    "parser.add_argument(\"-eps\", \"--eps\", help=\"Set epsilon of adam\", type=float, default=1e-7)\n",
    "parser.add_argument(\"-s\", \"--seed\", help=\"Set random seed\", type=int, default=1234)\n",
    "parser.add_argument(\"-sc\", \"--scaler\", help=\"Set random seed\", type=str, default='max30_federated')\n",
    "parser.add_argument(\"-li\", \"--log_interval\", help=\"Set log interval\", type=int, default=5)\n",
    "parser.add_argument(\"-mom\", \"--momentum\", help=\"Set momentum\", type=float, default=0.9)\n",
    "parser.add_argument(\"-fr\", \"--federated_ratio\", help=\"federated_ratio\", type=float, default=0.01)\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "max_x = 0\n",
    "\n",
    "def scale(arr, m, s):\n",
    "    arr = arr - m\n",
    "    arr = arr / (s + 1e-7)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def rescale(arr, m, s):\n",
    "    arr = arr * s\n",
    "    arr = arr + m\n",
    "    return arr\n",
    "\n",
    "\n",
    "def scale_minmax(arr, min, max):\n",
    "    arr = (arr - min) / (max - min)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def scale_maxabs(arr, maxabs):\n",
    "    arr = arr / maxabs\n",
    "    return arr\n",
    "\n",
    "\n",
    "def scale_robust(arr, q1, q3):\n",
    "    print('q1 : ', q1, 'q1 : ', q3)\n",
    "    arr = (arr - q1) / (q3-q1)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def return_maxabs_min_max(arr, q1, q3):\n",
    "    print('q1 : ', q1, 'q1 : ', q3)\n",
    "    arr = (arr - q1) / (q3-q1)\n",
    "    return arr\n",
    "\n",
    "MEAN = 61.9\n",
    "STD = 10.9\n",
    "\n",
    "_ = torch.manual_seed(args.seed)\n",
    "\n",
    "result_path = os.path.join('result_torch', 'from_fed_{}_fr{}_{}_{}_eps{}_ep{}_bs{}_lr{}_mom{}'.format(\n",
    "    args.scaler,\n",
    "    args.federated_ratio,\n",
    "    args.model_type,\n",
    "    args.loss_type,\n",
    "    args.eps,\n",
    "    args.epochs,\n",
    "    args.batch_size,\n",
    "    args.lr,\n",
    "    args.momentum\n",
    "))\n",
    "\n",
    "\n",
    "result_path_saved = os.path.join('result_torch', 'fed_{}_fr{}_{}_{}_eps{}_ep{}_bs{}_lr{}_mom{}'.format(\n",
    "    args.scaler,\n",
    "    args.federated_ratio,\n",
    "    args.model_type,\n",
    "    args.loss_type,\n",
    "    args.eps,\n",
    "    args.epochs_saved,\n",
    "    args.batch_size,\n",
    "    args.lr,\n",
    "    args.momentum\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TorchDataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATAPATH = '../data/ecg/text_demo_5500'\n",
    "train_file_suffix = 'train'\n",
    "test_file_suffix = 'test'\n",
    "\n",
    "file_name_train_x = 'X{}'.format(train_file_suffix)\n",
    "file_name_train_y = 'y{}'.format(train_file_suffix)\n",
    "file_name_test_x = 'X{}'.format(test_file_suffix)\n",
    "file_name_test_y = 'y{}'.format(test_file_suffix)\n",
    "\n",
    "print('Converting to TorchDataset...')\n",
    "\n",
    "train_x = np.loadtxt('{}/{}'.format(DATAPATH, file_name_train_x), delimiter=',')\n",
    "test_x = np.loadtxt('{}/{}'.format(DATAPATH, file_name_test_x), delimiter=',')\n",
    "\n",
    "total_x = np.vstack((train_x, test_x))\n",
    "\n",
    "train_y = np.loadtxt('{}/{}'.format(DATAPATH, file_name_train_y), delimiter=',')\n",
    "test_y = np.loadtxt('{}/{}'.format(DATAPATH, file_name_test_y), delimiter=',')\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], 3, 500)\n",
    "test_x = test_x.reshape(test_x.shape[0], 3, 500)\n",
    "\n",
    "result_array = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "federated_instance_count =  int(train_x.shape[0] * args.federated_ratio)\n",
    "train_x = train_x[federated_instance_count:, :, :]\n",
    "train_y = train_y[federated_instance_count:]\n",
    "\n",
    "batches = int((5000-federated_instance_count) / args.batch_size)\n",
    "log_batches = int(batches / args.log_interval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Dataset Train/Test split finished...\n"
     ]
    }
   ],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).float()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(data, [args.n_train_items, args.n_test_items])\n",
    "train_dataset = ECGDataset(train_x, train_y, transform=False)\n",
    "test_dataset = ECGDataset(test_x, test_y, transform=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "print('Torch Dataset Train/Test split finished...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class CNNAVG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAVG, self).__init__()\n",
    "        self.kernel_size = 7\n",
    "        self.padding_size = 0\n",
    "        self.channel_size = 6\n",
    "        self.avgpool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.avgpool2 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.avgpool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.fc1 = nn.Linear(372, 16)\n",
    "        self.fc2 = nn.Linear(16, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        # self.max_x = max_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # 32\n",
    "        x = self.avgpool1(x)  # 32\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.avgpool2(x)\n",
    "        y = F.relu(self.conv3(x))\n",
    "\n",
    "        y = self.avgpool3(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = F.relu(self.fc1(y))\n",
    "\n",
    "        y = F.relu(self.fc2(y))\n",
    "\n",
    "        y = self.fc3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CNNMAX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNMAX, self).__init__()\n",
    "        self.kernel_size = 7\n",
    "        self.padding_size = 0\n",
    "        self.channel_size = 6\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv1d(3, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.conv2 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.conv3 = nn.Conv1d(self.channel_size, self.channel_size, kernel_size=self.kernel_size,\n",
    "                               padding=(self.kernel_size // 2))\n",
    "        self.fc1 = nn.Linear(372, 16)\n",
    "        self.fc2 = nn.Linear(16, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # 32\n",
    "        x = self.maxpool1(x)  # 32\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        y = F.relu(self.conv3(x))\n",
    "        y = self.maxpool3(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = self.fc3(y)\n",
    "        return y\n",
    "\n",
    "def report_scores(X, y, trained_model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = trained_model(torch.from_numpy(X).float())\n",
    "        # output rescale\n",
    "        scores = rescale(scores, MEAN, STD)\n",
    "        y = rescale(y, MEAN, STD)\n",
    "\n",
    "        mse_loss = mean_squared_error(y, scores)\n",
    "\n",
    "        y_true.extend(list(y))\n",
    "        y_pred.extend(scores)\n",
    "\n",
    "    return y_true, y_pred, mse_loss\n",
    "\n",
    "\n",
    "def train(args, model, private_train_loader, optimizer, epoch, test_loader):\n",
    "    training_step = log_batches * (epoch-1)\n",
    "    model.train()\n",
    "    data_count = 0\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(private_train_loader):  # <-- now it is a private dataset\n",
    "        # if target.min() < 25 or target.max() > 140:\n",
    "        #     continue\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "        batch_size = output.shape[0]\n",
    "\n",
    "        # Reshape\n",
    "        # output = output.view(-1)\n",
    "        # target = target.view(-1)\n",
    "\n",
    "        target = target.view(target.shape[0], 1)\n",
    "        # r2 : 0.67 with smooth l1 loss\n",
    "        # loss = F.smooth_l1_loss(output, target).sum() / batch_size\n",
    "\n",
    "        # r2 : 0.7  with logcosh loss\n",
    "        # loss = (torch.log(torch.cosh(output - target))).sum() / batch_size\n",
    "\n",
    "        # r2 : 0.646 w mse loss\n",
    "        loss = ((output - target) ** 2).sum() / batch_size\n",
    "        # loss = ((output - target) ** 2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss = loss.item()\n",
    "        data_count += 1\n",
    "\n",
    "        print('batch_idx', batch_idx, batches)\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            # loss = loss.get().float_precision()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
    "                       100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))\n",
    "\n",
    "            # if args.is_comet:\n",
    "            #     training_step = training_step + 1\n",
    "            #     y_true_train, y_pred_train, train_mse_loss = report_scores(train_x, train_y, model)\n",
    "            #     _, train_r = r_mse(y_true_train, y_pred_train, train_mse_loss)\n",
    "            #     print('step : ', training_step)\n",
    "            #     experiment.log_metric(\"train_mse\", train_mse_loss, epoch=epoch, step=training_step)\n",
    "            #     experiment.log_metric(\"train_r\", train_r, epoch=epoch, step=training_step)\n",
    "\n",
    "            # test during training\n",
    "            test(args, model, test_loader, epoch, batch_idx, training_step)\n",
    "\n",
    "        if batch_idx % batches == 0:\n",
    "            test(args, model, test_loader, epoch, batch_idx, training_step)\n",
    "\n",
    "\n",
    "def test(args, model, private_test_loader, epoch, batch=999, step=0):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    data_count = 0\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in private_test_loader:\n",
    "            start_time = time.time()\n",
    "\n",
    "            output = model(data)\n",
    "            #\n",
    "            # output rescale\n",
    "            output = rescale(output, MEAN, STD)\n",
    "            target = rescale(target, MEAN, STD)\n",
    "\n",
    "            # Reshape\n",
    "            # output = output.view(-1)\n",
    "            # target = target.view(-1)\n",
    "\n",
    "            target = target.view(target.shape[0], 1)\n",
    "\n",
    "            test_loss += ((output - target) ** 2).sum()\n",
    "            # test_loss += torch.log(torch.cosh(output - target)).sum()\n",
    "\n",
    "            data_count += len(output)\n",
    "            pred_list.extend(output.numpy())\n",
    "            target_list.extend(target.numpy())\n",
    "            # print('rmse:', torch.sqrt(((output - target) ** 2).sum() / args.batch_size))\n",
    "            # print('r2score:', r2_score(target_list, pred_list))\n",
    "\n",
    "    # test_loss = test_loss.get().float_precision()\n",
    "    # print('Test set: Loss: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime: {:.3f}s'.format(batch_idx * args.batch_size, len(private_train_loader) * args.batch_size,\n",
    "    #            100. * batch_idx / len(private_train_loader), loss.item(), time.time() - start_time))\n",
    "    print('\\nTest set: Loss: avg MSE ({:.4f})\\tTime: {:.3f}s'.format(test_loss / data_count, time.time() - start_time))\n",
    "\n",
    "\n",
    "    # # output rescale\n",
    "    # target_list = rescale(target_list, MEAN, STD)\n",
    "    # pred_list = rescale(pred_list, MEAN, STD)\n",
    "\n",
    "    rm, test_r = r_mse(target_list, pred_list)\n",
    "\n",
    "    if batch == batches:\n",
    "        scatter_plot(target_list, pred_list, epoch, rm, batch)\n",
    "    #\n",
    "    #\n",
    "    # if args.is_comet:\n",
    "    #     experiment.log_metric(\"test_mse\", test_loss / data_count, epoch=epoch, step=step)\n",
    "    #     experiment.log_metric(\"test_r\", test_r, epoch=epoch, step=step)\n",
    "\n",
    "    if batch % args.log_interval == 0:\n",
    "        result = dict()\n",
    "        result['mse_test'] = test_loss.numpy() / data_count\n",
    "        result['r_test'] = test_r\n",
    "        result_array.append(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def scatter_plot(y_true, y_pred, epoch, message, batch):\n",
    "    result = np.column_stack((y_true,y_pred))\n",
    "\n",
    "    if not os.path.exists('{}/{}'.format(result_path, 'csv')):\n",
    "        os.makedirs('{}/{}'.format(result_path, 'csv'))\n",
    "\n",
    "    if not os.path.exists('{}/{}'.format(result_path, 'scatter')):\n",
    "        os.makedirs('{}/{}'.format(result_path, 'scatter'))\n",
    "\n",
    "    pd.DataFrame(result).to_csv(\"{}/csv/{}.csv\".format(result_path, epoch), index=False)\n",
    "\n",
    "    import matplotlib.lines as mlines\n",
    "    fig, ax = plt.subplots()\n",
    "    line = mlines.Line2D([0, 1], [0, 1], color='red')\n",
    "\n",
    "    ax.scatter(y_pred, y_true, s=3)\n",
    "\n",
    "    transform = ax.transAxes\n",
    "    line.set_transform(transform)\n",
    "    ax.add_line(line)\n",
    "\n",
    "    plt.suptitle(message)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Actual')\n",
    "    # set axes range\n",
    "    plt.xlim(30, 110)\n",
    "    plt.ylim(30, 110)\n",
    "\n",
    "    # plt.savefig(\"{}/scatter/{}.png\".format(result_path, epoch))\n",
    "\n",
    "    if args.is_comet:\n",
    "        experiment.log_figure(figure=plt, figure_name='{}_{}.png'.format(epoch, batch))\n",
    "    else:\n",
    "        plt.savefig(\"{}/scatter/{}_{}.png\".format(result_path, epoch, batch), dpi=600)\n",
    "    plt.clf()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def r_mse(y_true, y_pred, sample_weight=None, multioutput=None):\n",
    "\n",
    "    # r2 = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    # bounds_check = np.min(y_pred) > MIN_MOISTURE_BOUND\n",
    "    # bounds_check = bounds_check&(np.max(y_pred) < MAX_MOISTURE_BOUND)\n",
    "\n",
    "    y_true = np.array(y_true, dtype=np.float)\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = np.array(y_pred, dtype=np.float)\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    r = stats.pearsonr(y_true, y_pred)[0]\n",
    "    r2 = r**2\n",
    "\n",
    "    print('Scoring - std', np.std(y_true), np.std(y_pred))\n",
    "    print('Scoring - median', np.median(y_true), np.median(y_pred))\n",
    "    print('Scoring - min', np.min(y_true), np.min(y_pred))\n",
    "    print('Scoring - max', np.max(y_true), np.max(y_pred))\n",
    "    print('Scoring - mean', np.mean(y_true), np.mean(y_pred))\n",
    "    print('Scoring - MSE: ', mse, 'RMSE: ', math.sqrt(mse))\n",
    "    print('Scoring - R2: ', r2)\n",
    "    # print(y_pred)\n",
    "\n",
    "\n",
    "    result_message = 'r:{:.3f}, mse:{:.3f}, std:{:.3f},{:.3f}'.format(r, mse, np.std(y_true), np.std(y_pred))\n",
    "    return result_message, r\n",
    "\n",
    "def save_model(model, path):\n",
    "\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def transform_array(torch_array, ):\n",
    "    p = torch_array.detach().numpy()\n",
    "    print('p:', p.shape, p.ndim)\n",
    "    # if conv1d\n",
    "    if p.ndim == 3:\n",
    "        p = p.reshape(p.shape[0], -1)\n",
    "    p = np.transpose(p)\n",
    "    p = np.round_(p, 7)\n",
    "    return p\n",
    "\n",
    "def save_model_to_txt(model, path, ep):\n",
    "\n",
    "    conv1_weight = transform_array(model.conv1.weight)\n",
    "    conv1_bias = transform_array(model.conv1.bias)\n",
    "\n",
    "    conv2_weight = transform_array(model.conv2.weight)\n",
    "    conv2_bias = transform_array(model.conv2.bias)\n",
    "\n",
    "\n",
    "    conv3_weight = transform_array(model.conv3.weight)\n",
    "    conv3_bias = transform_array(model.conv3.bias)\n",
    "\n",
    "    fc1_weight = transform_array(model.fc1.weight)\n",
    "    fc1_bias = transform_array(model.fc1.bias)\n",
    "\n",
    "    fc2_weight = transform_array(model.fc2.weight)\n",
    "    fc2_bias = transform_array(model.fc2.bias)\n",
    "\n",
    "    fc3_weight = transform_array(model.fc3.weight)\n",
    "    fc3_bias = transform_array(model.fc3.bias)\n",
    "\n",
    "    np.savetxt('{}ecg_P1_{}_0_W0.bin'.format(path, ep), conv1_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b0.bin'.format(path, ep), conv1_bias, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_W1.bin'.format(path, ep), conv2_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b1.bin'.format(path, ep), conv2_bias, fmt='%1.7f')\n",
    "\n",
    "    np.savetxt('{}ecg_P1_{}_0_W2.bin'.format(path, ep), conv3_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b2.bin'.format(path, ep), conv3_bias, fmt='%1.7f')\n",
    "\n",
    "    np.savetxt('{}ecg_P1_{}_0_W3.bin'.format(path, ep), fc1_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b3.bin'.format(path, ep), fc1_bias, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_W4.bin'.format(path, ep), fc2_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b4.bin'.format(path, ep), fc2_bias, fmt='%1.7f')\n",
    "\n",
    "    np.savetxt('{}ecg_P1_{}_0_W5.bin'.format(path, ep), fc3_weight, fmt='%1.7f')\n",
    "    np.savetxt('{}ecg_P1_{}_0_b5.bin'.format(path, ep), fc3_bias, fmt='%1.7f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNMAX(\n",
      "  (maxpool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (maxpool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (maxpool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv1d(3, 6, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (conv2): Conv1d(6, 6, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (conv3): Conv1d(6, 6, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (fc1): Linear(in_features=372, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[[-0.2056, -0.0428, -0.1048, -0.0582, -0.1928,  0.0876, -0.1956],\n",
      "         [-0.0139,  0.0759, -0.0736,  0.1238,  0.0275,  0.1200,  0.1400],\n",
      "         [-0.0963,  0.0793, -0.0944,  0.0684, -0.1140,  0.1009,  0.0442]],\n",
      "\n",
      "        [[-0.0854, -0.1070,  0.0565,  0.2036,  0.1047, -0.0211, -0.0106],\n",
      "         [ 0.1240, -0.1517,  0.0725, -0.0723,  0.1263, -0.0778,  0.0108],\n",
      "         [ 0.0737,  0.1500, -0.0321,  0.1991, -0.1846, -0.0389, -0.2176]],\n",
      "\n",
      "        [[ 0.0181,  0.0619, -0.0883,  0.0906, -0.0354, -0.1896,  0.1675],\n",
      "         [ 0.1345,  0.1103,  0.1741,  0.0802,  0.1160,  0.1811, -0.0440],\n",
      "         [-0.1702, -0.1073, -0.0291, -0.0240, -0.0015,  0.1251,  0.0700]],\n",
      "\n",
      "        [[-0.1613, -0.0656, -0.0513,  0.1328, -0.0792, -0.0913, -0.0351],\n",
      "         [-0.0555, -0.0537, -0.2135,  0.1944,  0.1161, -0.1033, -0.1362],\n",
      "         [ 0.0076,  0.1243, -0.1566, -0.0824,  0.0913, -0.1408, -0.0243]],\n",
      "\n",
      "        [[-0.1646,  0.2024,  0.1176, -0.2017, -0.1205,  0.0774,  0.0120],\n",
      "         [ 0.0578, -0.1785, -0.1168,  0.0990, -0.1664, -0.0458,  0.0960],\n",
      "         [ 0.1133,  0.0136,  0.0633,  0.0971, -0.0255, -0.0596,  0.1666]],\n",
      "\n",
      "        [[ 0.2127,  0.1011, -0.0954, -0.1898, -0.2154,  0.0015, -0.0837],\n",
      "         [-0.0549, -0.0307,  0.2064,  0.2068, -0.0204, -0.0655,  0.1060],\n",
      "         [-0.0174, -0.2076,  0.0711,  0.2089, -0.1730, -0.0471,  0.0473]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "if args.model_type in ['shallow', 'ann', 'cnn2d', 'cann', 'cnnavg', 'cnnmax']:\n",
    "\n",
    "    if args.model_type == 'cnnavg':\n",
    "        model = CNNAVG()\n",
    "    elif args.model_type == 'cnnmax':\n",
    "        model = CNNMAX()\n",
    "\n",
    "    # if args.model_type == 'cnn2d':\n",
    "    #     summary(model, input_size=(3, 500, 1), batch_size=args.batch_size)\n",
    "    # else:\n",
    "    #     summary(model, input_size=(3, 500), batch_size=args.batch_size)\n",
    "# else:\n",
    "#     model = ML4CVD()\n",
    "#     summary(model, input_size=(12, 5000), batch_size=args.batch_size)\n",
    "\n",
    "print(model)\n",
    "print(model.conv1.weight)\n",
    "\n",
    "# save_model_to_txt(model, \"{}/models/\".format(result_path), 0)\n",
    "# exit(0)\n",
    "# model = model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "# for 12channel\n",
    "\n",
    "# for 1 channel\n",
    "# summary(model, input_size =(1, 12, 5000), batch_size=args.batch_size)\n",
    "# exit()\n",
    "\n",
    "if args.loss_type == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, eps=args.eps)  # 4.58\n",
    "elif args.loss_type == 'asgd':\n",
    "    optimizer = optim.ASGD(model.parameters(), lr=args.lr)  # 4.58\n",
    "elif args.loss_type == 'lbfgs':\n",
    "    optimizer = optim.LBFGS(model.parameters(), lr=args.lr)  # 4.58\n",
    "elif args.loss_type == 'adadelta':\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)  # 4.58\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, nesterov=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2073, -0.0456, -0.1082, -0.0622, -0.1953,  0.0895, -0.1925],\n",
      "         [-0.0162,  0.0727, -0.0758,  0.1224,  0.0268,  0.1259,  0.1455],\n",
      "         [-0.0969,  0.0789, -0.0933,  0.0710, -0.1122,  0.1049,  0.0466]],\n",
      "\n",
      "        [[-0.0864, -0.1116,  0.0565,  0.2097,  0.1002, -0.0226, -0.0090],\n",
      "         [ 0.1226, -0.1545,  0.0711, -0.0649,  0.1297, -0.0757,  0.0146],\n",
      "         [ 0.0732,  0.1516, -0.0336,  0.2005, -0.1766, -0.0352, -0.2153]],\n",
      "\n",
      "        [[ 0.0390,  0.0824, -0.0871,  0.0935, -0.0335, -0.1903,  0.1755],\n",
      "         [ 0.1440,  0.1178,  0.1691,  0.0776,  0.1132,  0.1760, -0.0498],\n",
      "         [-0.1816, -0.1203, -0.0353, -0.0296, -0.0061,  0.1207,  0.0562]],\n",
      "\n",
      "        [[-0.1616, -0.0677, -0.0436,  0.1617, -0.0687, -0.0989, -0.0355],\n",
      "         [-0.0674, -0.0659, -0.2149,  0.2118,  0.1217, -0.1149, -0.1444],\n",
      "         [-0.0040,  0.1142, -0.1657, -0.0939,  0.0864, -0.1448, -0.0321]],\n",
      "\n",
      "        [[-0.1627,  0.2009,  0.1209, -0.2002, -0.1223,  0.0760,  0.0165],\n",
      "         [ 0.0547, -0.1813, -0.1208,  0.0918, -0.1728, -0.0488,  0.0997],\n",
      "         [ 0.1083,  0.0123,  0.0560,  0.0883, -0.0300, -0.0613,  0.1659]],\n",
      "\n",
      "        [[ 0.2380,  0.1147, -0.0973, -0.1830, -0.2141,  0.0060, -0.0778],\n",
      "         [-0.0393, -0.0268,  0.2033,  0.2149, -0.0285, -0.0723,  0.1047],\n",
      "         [-0.0271, -0.2174,  0.0700,  0.2101, -0.1823, -0.0584,  0.0401]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Load Model from previous saved model\n",
    "model.load_state_dict(torch.load(\"{}/models/ep{}.h5\".format(result_path_saved, args.epochs_saved)))\n",
    "model.eval()\n",
    "print(model.conv1.weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: (6, 3, 7) 3\n",
      "p: (6,) 1\n",
      "p: (6, 6, 7) 3\n",
      "p: (6,) 1\n",
      "p: (6, 6, 7) 3\n",
      "p: (6,) 1\n",
      "p: (16, 372) 2\n",
      "p: (16,) 1\n",
      "p: (64, 16) 2\n",
      "p: (64,) 1\n",
      "p: (1, 64) 2\n",
      "p: (1,) 1\n",
      "batch_idx 0 154\n",
      "Train Epoch: 1 [0/4960 (0%)]\tLoss: 1.126132\tTime: 0.021s\n",
      "\n",
      "Test set: Loss: avg MSE (87.1776)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.8616091825375718\n",
      "Scoring - median 60.99966049194336 63.67472457885742\n",
      "Scoring - min 30.000062942504883 61.98932647705078\n",
      "Scoring - max 99.99986267089844 67.26333618164062\n",
      "Scoring - mean 61.45395826339722 63.81239324951172\n",
      "Scoring - MSE:  87.177605 RMSE:  9.336894809051506\n",
      "Scoring - R2:  0.12926438205104415\n",
      "\n",
      "Test set: Loss: avg MSE (87.1776)\tTime: 0.003s\n",
      "Scoring - std 9.308054141185021 0.8616091825375718\n",
      "Scoring - median 60.99966049194336 63.67472457885742\n",
      "Scoring - min 30.000062942504883 61.98932647705078\n",
      "Scoring - max 99.99986267089844 67.26333618164062\n",
      "Scoring - mean 61.45395826339722 63.81239324951172\n",
      "Scoring - MSE:  87.177605 RMSE:  9.336894809051506\n",
      "Scoring - R2:  0.12926438205104415\n",
      "batch_idx 1 154\n",
      "batch_idx 2 154\n",
      "batch_idx 3 154\n",
      "batch_idx 4 154\n",
      "batch_idx 5 154\n",
      "Train Epoch: 1 [160/4960 (3%)]\tLoss: 1.183511\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (83.6894)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.4834799054088372\n",
      "Scoring - median 60.99966049194336 61.30138969421387\n",
      "Scoring - min 30.000062942504883 59.79954528808594\n",
      "Scoring - max 99.99986267089844 63.84417724609375\n",
      "Scoring - mean 61.45395826339722 61.383500007629394\n",
      "Scoring - MSE:  83.689445 RMSE:  9.148193564611839\n",
      "Scoring - R2:  0.12554904318313417\n",
      "batch_idx 6 154\n",
      "batch_idx 7 154\n",
      "batch_idx 8 154\n",
      "batch_idx 9 154\n",
      "batch_idx 10 154\n",
      "Train Epoch: 1 [320/4960 (6%)]\tLoss: 0.929291\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (83.6204)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.1393984881795765\n",
      "Scoring - median 60.99966049194336 63.233428955078125\n",
      "Scoring - min 30.000062942504883 60.802001953125\n",
      "Scoring - max 99.99986267089844 68.02146911621094\n",
      "Scoring - mean 61.45395826339722 63.41601077270508\n",
      "Scoring - MSE:  83.6204 RMSE:  9.144419034312548\n",
      "Scoring - R2:  0.14826333897213215\n",
      "batch_idx 11 154\n",
      "batch_idx 12 154\n",
      "batch_idx 13 154\n",
      "batch_idx 14 154\n",
      "batch_idx 15 154\n",
      "Train Epoch: 1 [480/4960 (10%)]\tLoss: 1.204130\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (93.7808)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.018807927626219\n",
      "Scoring - median 60.99966049194336 65.4716911315918\n",
      "Scoring - min 30.000062942504883 60.87970733642578\n",
      "Scoring - max 99.99986267089844 73.26470947265625\n",
      "Scoring - mean 61.45395826339722 65.73438298797608\n",
      "Scoring - MSE:  93.780815 RMSE:  9.684049520965479\n",
      "Scoring - R2:  0.16479808108352698\n",
      "batch_idx 16 154\n",
      "batch_idx 17 154\n",
      "batch_idx 18 154\n",
      "batch_idx 19 154\n",
      "batch_idx 20 154\n",
      "Train Epoch: 1 [640/4960 (13%)]\tLoss: 0.876164\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (82.4299)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.0325738072395902\n",
      "Scoring - median 60.99966049194336 59.62976837158203\n",
      "Scoring - min 30.000062942504883 57.19688034057617\n",
      "Scoring - max 99.99986267089844 64.59652709960938\n",
      "Scoring - mean 61.45395826339722 59.80378022003174\n",
      "Scoring - MSE:  82.42986 RMSE:  9.079089325261329\n",
      "Scoring - R2:  0.17317504060107664\n",
      "batch_idx 21 154\n",
      "batch_idx 22 154\n",
      "batch_idx 23 154\n",
      "batch_idx 24 154\n",
      "batch_idx 25 154\n",
      "Train Epoch: 1 [800/4960 (16%)]\tLoss: 1.198148\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (83.3807)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 3.0972205974604883\n",
      "Scoring - median 60.99966049194336 64.71914291381836\n",
      "Scoring - min 30.000062942504883 58.43293762207031\n",
      "Scoring - max 99.99986267089844 76.56818389892578\n",
      "Scoring - mean 61.45395826339722 65.08041175079346\n",
      "Scoring - MSE:  83.38066 RMSE:  9.13130116745375\n",
      "Scoring - R2:  0.20339010467531776\n",
      "batch_idx 26 154\n",
      "batch_idx 27 154\n",
      "batch_idx 28 154\n",
      "batch_idx 29 154\n",
      "batch_idx 30 154\n",
      "Train Epoch: 1 [960/4960 (19%)]\tLoss: 0.534875\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (70.8572)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.444026717303117\n",
      "Scoring - median 60.99966049194336 59.81405258178711\n",
      "Scoring - min 30.000062942504883 53.80949020385742\n",
      "Scoring - max 99.99986267089844 69.31669616699219\n",
      "Scoring - mean 61.45395826339722 60.15672536468506\n",
      "Scoring - MSE:  70.85725 RMSE:  8.41767464320912\n",
      "Scoring - R2:  0.2653857390833202\n",
      "batch_idx 31 154\n",
      "batch_idx 32 154\n",
      "batch_idx 33 154\n",
      "batch_idx 34 154\n",
      "batch_idx 35 154\n",
      "Train Epoch: 1 [1120/4960 (23%)]\tLoss: 0.827572\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (77.6131)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 4.9986736596545125\n",
      "Scoring - median 60.99966049194336 65.2071533203125\n",
      "Scoring - min 30.000062942504883 54.146217346191406\n",
      "Scoring - max 99.99986267089844 81.35108184814453\n",
      "Scoring - mean 61.45395826339722 65.64834706115722\n",
      "Scoring - MSE:  77.61309 RMSE:  8.809829198976376\n",
      "Scoring - R2:  0.3075530125552945\n",
      "batch_idx 36 154\n",
      "batch_idx 37 154\n",
      "batch_idx 38 154\n",
      "batch_idx 39 154\n",
      "batch_idx 40 154\n",
      "Train Epoch: 1 [1280/4960 (26%)]\tLoss: 0.680943\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (88.5435)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.0656440138064855\n",
      "Scoring - median 60.99966049194336 66.79798126220703\n",
      "Scoring - min 30.000062942504883 54.82976531982422\n",
      "Scoring - max 99.99986267089844 85.63629150390625\n",
      "Scoring - mean 61.45395826339722 67.09448968505859\n",
      "Scoring - MSE:  88.54345 RMSE:  9.4097528873959\n",
      "Scoring - R2:  0.3489576600793366\n",
      "batch_idx 41 154\n",
      "batch_idx 42 154\n",
      "batch_idx 43 154\n",
      "batch_idx 44 154\n",
      "batch_idx 45 154\n",
      "Train Epoch: 1 [1440/4960 (29%)]\tLoss: 0.442403\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (47.8234)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 5.934285759286874\n",
      "Scoring - median 60.99966049194336 61.276668548583984\n",
      "Scoring - min 30.000062942504883 44.990379333496094\n",
      "Scoring - max 99.99986267089844 77.45277404785156\n",
      "Scoring - mean 61.45395826339722 61.40173205566406\n",
      "Scoring - MSE:  47.823364 RMSE:  6.9154438944880825\n",
      "Scoring - R2:  0.44911677828901103\n",
      "batch_idx 46 154\n",
      "batch_idx 47 154\n",
      "batch_idx 48 154\n",
      "batch_idx 49 154\n",
      "batch_idx 50 154\n",
      "Train Epoch: 1 [1600/4960 (32%)]\tLoss: 0.191065\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (46.5561)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.552344534780567\n",
      "Scoring - median 60.99966049194336 59.34180450439453\n",
      "Scoring - min 30.000062942504883 39.866844177246094\n",
      "Scoring - max 99.99986267089844 77.35369110107422\n",
      "Scoring - mean 61.45395826339722 59.0600217666626\n",
      "Scoring - MSE:  46.556053 RMSE:  6.823199627859432\n",
      "Scoring - R2:  0.5293532913261094\n",
      "batch_idx 51 154\n",
      "batch_idx 52 154\n",
      "batch_idx 53 154\n",
      "batch_idx 54 154\n",
      "batch_idx 55 154\n",
      "Train Epoch: 1 [1760/4960 (35%)]\tLoss: 1.637737\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (176.6294)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.3561038409921613\n",
      "Scoring - median 60.99966049194336 52.08555221557617\n",
      "Scoring - min 30.000062942504883 36.261260986328125\n",
      "Scoring - max 99.99986267089844 54.38035583496094\n",
      "Scoring - mean 61.45395826339722 51.44507643890381\n",
      "Scoring - MSE:  176.62944 RMSE:  13.290200912989134\n",
      "Scoring - R2:  0.12876835007732193\n",
      "batch_idx 56 154\n",
      "batch_idx 57 154\n",
      "batch_idx 58 154\n",
      "batch_idx 59 154\n",
      "batch_idx 60 154\n",
      "Train Epoch: 1 [1920/4960 (39%)]\tLoss: 1.220678\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (97.6223)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.15988662149727667\n",
      "Scoring - median 60.99966049194336 57.99551010131836\n",
      "Scoring - min 30.000062942504883 56.451751708984375\n",
      "Scoring - max 99.99986267089844 58.40555191040039\n",
      "Scoring - mean 61.45395826339722 57.99865032958984\n",
      "Scoring - MSE:  97.62233 RMSE:  9.880401293060624\n",
      "Scoring - R2:  0.10890568749318431\n",
      "batch_idx 61 154\n",
      "batch_idx 62 154\n",
      "batch_idx 63 154\n",
      "batch_idx 64 154\n",
      "batch_idx 65 154\n",
      "Train Epoch: 1 [2080/4960 (42%)]\tLoss: 0.644586\tTime: 0.010s\n",
      "\n",
      "Test set: Loss: avg MSE (87.6965)\tTime: 0.003s\n",
      "Scoring - std 9.308054141185021 0.09690762323818806\n",
      "Scoring - median 60.99966049194336 62.61393356323242\n",
      "Scoring - min 30.000062942504883 62.484710693359375\n",
      "Scoring - max 99.99986267089844 63.1014289855957\n",
      "Scoring - mean 61.45395826339722 62.639168891906735\n",
      "Scoring - MSE:  87.69648 RMSE:  9.364639864797967\n",
      "Scoring - R2:  0.03927246991375986\n",
      "batch_idx 66 154\n",
      "batch_idx 67 154\n",
      "batch_idx 68 154\n",
      "batch_idx 69 154\n",
      "batch_idx 70 154\n",
      "Train Epoch: 1 [2240/4960 (45%)]\tLoss: 1.507475\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (96.3535)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.09597526281734386\n",
      "Scoring - median 60.99966049194336 64.59836959838867\n",
      "Scoring - min 30.000062942504883 64.45867919921875\n",
      "Scoring - max 99.99986267089844 65.10783386230469\n",
      "Scoring - mean 61.45395826339722 64.62253077697754\n",
      "Scoring - MSE:  96.35344 RMSE:  9.815978776008773\n",
      "Scoring - R2:  0.03525903590901851\n",
      "batch_idx 71 154\n",
      "batch_idx 72 154\n",
      "batch_idx 73 154\n",
      "batch_idx 74 154\n",
      "batch_idx 75 154\n",
      "Train Epoch: 1 [2400/4960 (48%)]\tLoss: 0.720154\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (93.4594)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.08765053289618795\n",
      "Scoring - median 60.99966049194336 64.09473419189453\n",
      "Scoring - min 30.000062942504883 63.96827697753906\n",
      "Scoring - max 99.99986267089844 64.59761810302734\n",
      "Scoring - mean 61.45395826339722 64.11615839385986\n",
      "Scoring - MSE:  93.45935 RMSE:  9.667437643240193\n",
      "Scoring - R2:  0.028509882106350408\n",
      "batch_idx 76 154\n",
      "batch_idx 77 154\n",
      "batch_idx 78 154\n",
      "batch_idx 79 154\n",
      "batch_idx 80 154\n",
      "Train Epoch: 1 [2560/4960 (52%)]\tLoss: 1.402156\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (86.9101)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.0701842450677429\n",
      "Scoring - median 60.99966049194336 62.085933685302734\n",
      "Scoring - min 30.000062942504883 61.96808624267578\n",
      "Scoring - max 99.99986267089844 62.548423767089844\n",
      "Scoring - mean 61.45395826339722 62.10374843597412\n",
      "Scoring - MSE:  86.91008 RMSE:  9.322557586631186\n",
      "Scoring - R2:  0.014428514018512563\n",
      "batch_idx 81 154\n",
      "batch_idx 82 154\n",
      "batch_idx 83 154\n",
      "batch_idx 84 154\n",
      "batch_idx 85 154\n",
      "Train Epoch: 1 [2720/4960 (55%)]\tLoss: 1.825502\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (86.5066)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.07036239282337027\n",
      "Scoring - median 60.99966049194336 61.31342887878418\n",
      "Scoring - min 30.000062942504883 61.21009063720703\n",
      "Scoring - max 99.99986267089844 61.812774658203125\n",
      "Scoring - mean 61.45395826339722 61.329481315612796\n",
      "Scoring - MSE:  86.50656 RMSE:  9.300890348740644\n",
      "Scoring - R2:  0.013778056897712335\n",
      "batch_idx 86 154\n",
      "batch_idx 87 154\n",
      "batch_idx 88 154\n",
      "batch_idx 89 154\n",
      "batch_idx 90 154\n",
      "Train Epoch: 1 [2880/4960 (58%)]\tLoss: 1.325004\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (86.6663)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.08526711535342689\n",
      "Scoring - median 60.99966049194336 61.918739318847656\n",
      "Scoring - min 30.000062942504883 61.808624267578125\n",
      "Scoring - max 99.99986267089844 62.53489303588867\n",
      "Scoring - mean 61.45395826339722 61.941991821289065\n",
      "Scoring - MSE:  86.66625 RMSE:  9.309471098630173\n",
      "Scoring - R2:  0.019046200853010613\n",
      "batch_idx 91 154\n",
      "batch_idx 92 154\n",
      "batch_idx 93 154\n",
      "batch_idx 94 154\n",
      "batch_idx 95 154\n",
      "Train Epoch: 1 [3040/4960 (61%)]\tLoss: 0.460357\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (87.2425)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.10581855889303056\n",
      "Scoring - median 60.99966049194336 62.38035583496094\n",
      "Scoring - min 30.000062942504883 62.23719024658203\n",
      "Scoring - max 99.99986267089844 63.11408233642578\n",
      "Scoring - mean 61.45395826339722 62.40687141418457\n",
      "Scoring - MSE:  87.242485 RMSE:  9.340368571228156\n",
      "Scoring - R2:  0.02583414970050412\n",
      "batch_idx 96 154\n",
      "batch_idx 97 154\n",
      "batch_idx 98 154\n",
      "batch_idx 99 154\n",
      "batch_idx 100 154\n",
      "Train Epoch: 1 [3200/4960 (65%)]\tLoss: 1.069373\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (87.5937)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.13384046692546522\n",
      "Scoring - median 60.99966049194336 62.611520767211914\n",
      "Scoring - min 30.000062942504883 62.416934967041016\n",
      "Scoring - max 99.99986267089844 63.44224166870117\n",
      "Scoring - mean 61.45395826339722 62.63844669342041\n",
      "Scoring - MSE:  87.59375 RMSE:  9.359153273667442\n",
      "Scoring - R2:  0.03513762172198234\n",
      "batch_idx 101 154\n",
      "batch_idx 102 154\n",
      "batch_idx 103 154\n",
      "batch_idx 104 154\n",
      "batch_idx 105 154\n",
      "Train Epoch: 1 [3360/4960 (68%)]\tLoss: 0.900807\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (86.7076)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.1716386809789376\n",
      "Scoring - median 60.99966049194336 62.228811264038086\n",
      "Scoring - min 30.000062942504883 62.000640869140625\n",
      "Scoring - max 99.99986267089844 63.22906494140625\n",
      "Scoring - mean 61.45395826339722 62.27196614074707\n",
      "Scoring - MSE:  86.707596 RMSE:  9.311691351478276\n",
      "Scoring - R2:  0.03898413312990615\n",
      "batch_idx 106 154\n",
      "batch_idx 107 154\n",
      "batch_idx 108 154\n",
      "batch_idx 109 154\n",
      "batch_idx 110 154\n",
      "Train Epoch: 1 [3520/4960 (71%)]\tLoss: 0.717347\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (86.7251)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.227408689373307\n",
      "Scoring - median 60.99966049194336 62.36604309082031\n",
      "Scoring - min 30.000062942504883 62.0515251159668\n",
      "Scoring - max 99.99986267089844 63.502899169921875\n",
      "Scoring - mean 61.45395826339722 62.41881304168701\n",
      "Scoring - MSE:  86.72508 RMSE:  9.312630262039878\n",
      "Scoring - R2:  0.04493897805617721\n",
      "batch_idx 111 154\n",
      "batch_idx 112 154\n",
      "batch_idx 113 154\n",
      "batch_idx 114 154\n",
      "batch_idx 115 154\n",
      "Train Epoch: 1 [3680/4960 (74%)]\tLoss: 1.638295\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (85.8335)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.27271387457272156\n",
      "Scoring - median 60.99966049194336 61.870283126831055\n",
      "Scoring - min 30.000062942504883 61.498870849609375\n",
      "Scoring - max 99.99986267089844 63.18922424316406\n",
      "Scoring - mean 61.45395826339722 61.935434936523436\n",
      "Scoring - MSE:  85.83354 RMSE:  9.264639327578662\n",
      "Scoring - R2:  0.04802049023079468\n",
      "batch_idx 116 154\n",
      "batch_idx 117 154\n",
      "batch_idx 118 154\n",
      "batch_idx 119 154\n",
      "batch_idx 120 154\n",
      "Train Epoch: 1 [3840/4960 (77%)]\tLoss: 1.257204\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (85.3025)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.3502424416931464\n",
      "Scoring - median 60.99966049194336 61.728620529174805\n",
      "Scoring - min 30.000062942504883 61.19641876220703\n",
      "Scoring - max 99.99986267089844 63.177127838134766\n",
      "Scoring - mean 61.45395826339722 61.79847509765625\n",
      "Scoring - MSE:  85.30253 RMSE:  9.23593678959247\n",
      "Scoring - R2:  0.05862554990044342\n",
      "batch_idx 121 154\n",
      "batch_idx 122 154\n",
      "batch_idx 123 154\n",
      "batch_idx 124 154\n",
      "batch_idx 125 154\n",
      "Train Epoch: 1 [4000/4960 (81%)]\tLoss: 1.156565\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (86.5369)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.42985809198271907\n",
      "Scoring - median 60.99966049194336 62.838979721069336\n",
      "Scoring - min 30.000062942504883 61.83015823364258\n",
      "Scoring - max 99.99986267089844 64.1659164428711\n",
      "Scoring - mean 61.45395826339722 62.828317474365235\n",
      "Scoring - MSE:  86.53687 RMSE:  9.30251970509977\n",
      "Scoring - R2:  0.07398513152201486\n",
      "batch_idx 126 154\n",
      "batch_idx 127 154\n",
      "batch_idx 128 154\n",
      "batch_idx 129 154\n",
      "batch_idx 130 154\n",
      "Train Epoch: 1 [4160/4960 (84%)]\tLoss: 0.825595\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (87.7085)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.5272501242152545\n",
      "Scoring - median 60.99966049194336 63.331092834472656\n",
      "Scoring - min 30.000062942504883 62.03515625\n",
      "Scoring - max 99.99986267089844 65.12793731689453\n",
      "Scoring - mean 61.45395826339722 63.34797696685791\n",
      "Scoring - MSE:  87.70855 RMSE:  9.365284272221091\n",
      "Scoring - R2:  0.08118180348877693\n",
      "batch_idx 131 154\n",
      "batch_idx 132 154\n",
      "batch_idx 133 154\n",
      "batch_idx 134 154\n",
      "batch_idx 135 154\n",
      "Train Epoch: 1 [4320/4960 (87%)]\tLoss: 0.907270\tTime: 0.010s\n",
      "\n",
      "Test set: Loss: avg MSE (83.4311)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.7234986709501137\n",
      "Scoring - median 60.99966049194336 61.22898292541504\n",
      "Scoring - min 30.000062942504883 60.09073257446289\n",
      "Scoring - max 99.99986267089844 63.86933517456055\n",
      "Scoring - mean 61.45395826339722 61.37438423156738\n",
      "Scoring - MSE:  83.43109 RMSE:  9.134062147182586\n",
      "Scoring - R2:  0.07704686048410057\n",
      "batch_idx 136 154\n",
      "batch_idx 137 154\n",
      "batch_idx 138 154\n",
      "batch_idx 139 154\n",
      "batch_idx 140 154\n",
      "Train Epoch: 1 [4480/4960 (90%)]\tLoss: 0.918477\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (82.4496)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 0.9537268945797693\n",
      "Scoring - median 60.99966049194336 61.15783500671387\n",
      "Scoring - min 30.000062942504883 59.5454216003418\n",
      "Scoring - max 99.99986267089844 64.48284149169922\n",
      "Scoring - mean 61.45395826339722 61.30133292388916\n",
      "Scoring - MSE:  82.44959 RMSE:  9.080175801730494\n",
      "Scoring - R2:  0.08326294447185985\n",
      "batch_idx 141 154\n",
      "batch_idx 142 154\n",
      "batch_idx 143 154\n",
      "batch_idx 144 154\n",
      "batch_idx 145 154\n",
      "Train Epoch: 1 [4640/4960 (94%)]\tLoss: 1.095350\tTime: 0.010s\n",
      "\n",
      "Test set: Loss: avg MSE (85.0501)\tTime: 0.003s\n",
      "Scoring - std 9.308054141185021 1.1701776751618431\n",
      "Scoring - median 60.99966049194336 63.435142517089844\n",
      "Scoring - min 30.000062942504883 60.433799743652344\n",
      "Scoring - max 99.99986267089844 67.59715270996094\n",
      "Scoring - mean 61.45395826339722 63.45084822082519\n",
      "Scoring - MSE:  85.050125 RMSE:  9.22226247306323\n",
      "Scoring - R2:  0.1016873300404616\n",
      "batch_idx 146 154\n",
      "batch_idx 147 154\n",
      "batch_idx 148 154\n",
      "batch_idx 149 154\n",
      "batch_idx 150 154\n",
      "Train Epoch: 1 [4800/4960 (97%)]\tLoss: 0.926330\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (80.8952)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.4639809931520094\n",
      "Scoring - median 60.99966049194336 62.41434097290039\n",
      "Scoring - min 30.000062942504883 59.225067138671875\n",
      "Scoring - max 99.99986267089844 67.58683776855469\n",
      "Scoring - mean 61.45395826339722 62.346890632629396\n",
      "Scoring - MSE:  80.89523 RMSE:  8.994177736419093\n",
      "Scoring - R2:  0.10155732219933157\n",
      "batch_idx 151 154\n",
      "batch_idx 152 154\n",
      "batch_idx 153 154\n",
      "batch_idx 154 154\n",
      "\n",
      "Test set: Loss: avg MSE (81.4478)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.7484340157731344\n",
      "Scoring - median 60.99966049194336 63.14672660827637\n",
      "Scoring - min 30.000062942504883 59.19090270996094\n",
      "Scoring - max 99.99986267089844 69.56207275390625\n",
      "Scoring - mean 61.45395826339722 63.11893056488037\n",
      "Scoring - MSE:  81.447784 RMSE:  9.024842625986789\n",
      "Scoring - R2:  0.11465288950629383\n",
      "batch_idx 0 154\n",
      "Train Epoch: 2 [0/4960 (0%)]\tLoss: 1.022753\tTime: 0.010s\n",
      "\n",
      "Test set: Loss: avg MSE (80.6171)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.823155994391031\n",
      "Scoring - median 60.99966049194336 62.90057945251465\n",
      "Scoring - min 30.000062942504883 58.98512649536133\n",
      "Scoring - max 99.99986267089844 69.66222381591797\n",
      "Scoring - mean 61.45395826339722 62.87396684265137\n",
      "Scoring - MSE:  80.617096 RMSE:  8.978702353194787\n",
      "Scoring - R2:  0.11209027767820626\n",
      "\n",
      "Test set: Loss: avg MSE (80.6171)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.823155994391031\n",
      "Scoring - median 60.99966049194336 62.90057945251465\n",
      "Scoring - min 30.000062942504883 58.98512649536133\n",
      "Scoring - max 99.99986267089844 69.66222381591797\n",
      "Scoring - mean 61.45395826339722 62.87396684265137\n",
      "Scoring - MSE:  80.617096 RMSE:  8.978702353194787\n",
      "Scoring - R2:  0.11209027767820626\n",
      "batch_idx 1 154\n",
      "batch_idx 2 154\n",
      "batch_idx 3 154\n",
      "batch_idx 4 154\n",
      "batch_idx 5 154\n",
      "Train Epoch: 2 [160/4960 (3%)]\tLoss: 1.063165\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (77.8398)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 1.9534899271549366\n",
      "Scoring - median 60.99966049194336 61.37925910949707\n",
      "Scoring - min 30.000062942504883 58.013427734375\n",
      "Scoring - max 99.99986267089844 68.70873260498047\n",
      "Scoring - mean 61.45395826339722 61.5017260055542\n",
      "Scoring - MSE:  77.839806 RMSE:  8.8226869831717\n",
      "Scoring - R2:  0.12039640345237797\n",
      "batch_idx 6 154\n",
      "batch_idx 7 154\n",
      "batch_idx 8 154\n",
      "batch_idx 9 154\n",
      "batch_idx 10 154\n",
      "Train Epoch: 2 [320/4960 (6%)]\tLoss: 0.789907\tTime: 0.010s\n",
      "\n",
      "Test set: Loss: avg MSE (79.1415)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.345882183531158\n",
      "Scoring - median 60.99966049194336 63.84489631652832\n",
      "Scoring - min 30.000062942504883 57.90192794799805\n",
      "Scoring - max 99.99986267089844 72.9021987915039\n",
      "Scoring - mean 61.45395826339722 63.751771125793454\n",
      "Scoring - MSE:  79.14151 RMSE:  8.896151415627187\n",
      "Scoring - R2:  0.17523951213776845\n",
      "batch_idx 11 154\n",
      "batch_idx 12 154\n",
      "batch_idx 13 154\n",
      "batch_idx 14 154\n",
      "batch_idx 15 154\n",
      "Train Epoch: 2 [480/4960 (10%)]\tLoss: 1.104852\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (85.7335)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.8592629487167476\n",
      "Scoring - median 60.99966049194336 65.4674186706543\n",
      "Scoring - min 30.000062942504883 58.20619583129883\n",
      "Scoring - max 99.99986267089844 76.24598693847656\n",
      "Scoring - mean 61.45395826339722 65.64121550750733\n",
      "Scoring - MSE:  85.73354 RMSE:  9.259240972995363\n",
      "Scoring - R2:  0.25001234142792433\n",
      "batch_idx 16 154\n",
      "batch_idx 17 154\n",
      "batch_idx 18 154\n",
      "batch_idx 19 154\n",
      "batch_idx 20 154\n",
      "Train Epoch: 2 [640/4960 (13%)]\tLoss: 0.769796\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (69.8355)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 2.697507535789883\n",
      "Scoring - median 60.99966049194336 59.40670204162598\n",
      "Scoring - min 30.000062942504883 50.288143157958984\n",
      "Scoring - max 99.99986267089844 66.10877990722656\n",
      "Scoring - mean 61.45395826339722 59.56507187652588\n",
      "Scoring - MSE:  69.83555 RMSE:  8.356766623573911\n",
      "Scoring - R2:  0.3031435471697344\n",
      "batch_idx 21 154\n",
      "batch_idx 22 154\n",
      "batch_idx 23 154\n",
      "batch_idx 24 154\n",
      "batch_idx 25 154\n",
      "Train Epoch: 2 [800/4960 (16%)]\tLoss: 0.882109\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (60.9927)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 5.218009955572389\n",
      "Scoring - median 60.99966049194336 64.6472396850586\n",
      "Scoring - min 30.000062942504883 51.17616653442383\n",
      "Scoring - max 99.99986267089844 77.8462905883789\n",
      "Scoring - mean 61.45395826339722 64.21596541595459\n",
      "Scoring - MSE:  60.992683 RMSE:  7.809781265224048\n",
      "Scoring - R2:  0.3879478951051085\n",
      "batch_idx 26 154\n",
      "batch_idx 27 154\n",
      "batch_idx 28 154\n",
      "batch_idx 29 154\n",
      "batch_idx 30 154\n",
      "Train Epoch: 2 [960/4960 (19%)]\tLoss: 0.375730\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (62.3841)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.4183505185081104\n",
      "Scoring - median 60.99966049194336 58.92668342590332\n",
      "Scoring - min 30.000062942504883 28.103240966796875\n",
      "Scoring - max 99.99986267089844 70.84931945800781\n",
      "Scoring - mean 61.45395826339722 58.336220737457275\n",
      "Scoring - MSE:  62.384117 RMSE:  7.898361673566541\n",
      "Scoring - R2:  0.39580294981224695\n",
      "batch_idx 31 154\n",
      "batch_idx 32 154\n",
      "batch_idx 33 154\n",
      "batch_idx 34 154\n",
      "batch_idx 35 154\n",
      "Train Epoch: 2 [1120/4960 (23%)]\tLoss: 0.513390\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (63.2953)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.081031947451043\n",
      "Scoring - median 60.99966049194336 66.31377410888672\n",
      "Scoring - min 30.000062942504883 39.076446533203125\n",
      "Scoring - max 99.99986267089844 87.45356750488281\n",
      "Scoring - mean 61.45395826339722 65.16122843170166\n",
      "Scoring - MSE:  63.29532 RMSE:  7.955835506313314\n",
      "Scoring - R2:  0.4632508388015809\n",
      "batch_idx 36 154\n",
      "batch_idx 37 154\n",
      "batch_idx 38 154\n",
      "batch_idx 39 154\n",
      "batch_idx 40 154\n",
      "Train Epoch: 2 [1280/4960 (26%)]\tLoss: 0.457805\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (47.0241)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.990817815613339\n",
      "Scoring - median 60.99966049194336 63.376060485839844\n",
      "Scoring - min 30.000062942504883 44.95722961425781\n",
      "Scoring - max 99.99986267089844 82.25285339355469\n",
      "Scoring - mean 61.45395826339722 63.059179718017575\n",
      "Scoring - MSE:  47.02411 RMSE:  6.857412696252045\n",
      "Scoring - R2:  0.489620946726482\n",
      "batch_idx 41 154\n",
      "batch_idx 42 154\n",
      "batch_idx 43 154\n",
      "batch_idx 44 154\n",
      "batch_idx 45 154\n",
      "Train Epoch: 2 [1440/4960 (29%)]\tLoss: 0.387193\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (39.6406)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.430437893466987\n",
      "Scoring - median 60.99966049194336 62.18131065368652\n",
      "Scoring - min 30.000062942504883 37.162567138671875\n",
      "Scoring - max 99.99986267089844 79.0602035522461\n",
      "Scoring - mean 61.45395826339722 61.682080429077146\n",
      "Scoring - MSE:  39.640583 RMSE:  6.2960767973659655\n",
      "Scoring - R2:  0.5465478844699583\n",
      "batch_idx 46 154\n",
      "batch_idx 47 154\n",
      "batch_idx 48 154\n",
      "batch_idx 49 154\n",
      "batch_idx 50 154\n",
      "Train Epoch: 2 [1600/4960 (32%)]\tLoss: 0.243655\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (38.1226)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.997107389468492\n",
      "Scoring - median 60.99966049194336 59.70635795593262\n",
      "Scoring - min 30.000062942504883 38.49119567871094\n",
      "Scoring - max 99.99986267089844 76.28952026367188\n",
      "Scoring - mean 61.45395826339722 59.988285972595214\n",
      "Scoring - MSE:  38.122585 RMSE:  6.174348977554708\n",
      "Scoring - R2:  0.5849540557124159\n",
      "batch_idx 51 154\n",
      "batch_idx 52 154\n",
      "batch_idx 53 154\n",
      "batch_idx 54 154\n",
      "batch_idx 55 154\n",
      "Train Epoch: 2 [1760/4960 (35%)]\tLoss: 0.203734\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (54.6447)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.981063620267286\n",
      "Scoring - median 60.99966049194336 58.2067756652832\n",
      "Scoring - min 30.000062942504883 30.38100242614746\n",
      "Scoring - max 99.99986267089844 71.34266662597656\n",
      "Scoring - mean 61.45395826339722 57.37270623397827\n",
      "Scoring - MSE:  54.644684 RMSE:  7.392204261104439\n",
      "Scoring - R2:  0.5615410153076448\n",
      "batch_idx 56 154\n",
      "batch_idx 57 154\n",
      "batch_idx 58 154\n",
      "batch_idx 59 154\n",
      "batch_idx 60 154\n",
      "Train Epoch: 2 [1920/4960 (39%)]\tLoss: 0.187191\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (30.8118)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.561242332468631\n",
      "Scoring - median 60.99966049194336 60.876516342163086\n",
      "Scoring - min 30.000062942504883 38.14448547363281\n",
      "Scoring - max 99.99986267089844 79.5281982421875\n",
      "Scoring - mean 61.45395826339722 60.99001077270508\n",
      "Scoring - MSE:  30.81185 RMSE:  5.550842241868905\n",
      "Scoring - R2:  0.6469174562419073\n",
      "batch_idx 61 154\n",
      "batch_idx 62 154\n",
      "batch_idx 63 154\n",
      "batch_idx 64 154\n",
      "batch_idx 65 154\n",
      "Train Epoch: 2 [2080/4960 (42%)]\tLoss: 0.152899\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (33.0323)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.903093807918441\n",
      "Scoring - median 60.99966049194336 62.70638847351074\n",
      "Scoring - min 30.000062942504883 42.594573974609375\n",
      "Scoring - max 99.99986267089844 78.76042175292969\n",
      "Scoring - mean 61.45395826339722 62.61944548034668\n",
      "Scoring - MSE:  33.032253 RMSE:  5.747369247349683\n",
      "Scoring - R2:  0.6376575592454036\n",
      "batch_idx 66 154\n",
      "batch_idx 67 154\n",
      "batch_idx 68 154\n",
      "batch_idx 69 154\n",
      "batch_idx 70 154\n",
      "Train Epoch: 2 [2240/4960 (45%)]\tLoss: 0.925984\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (72.2778)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.104626234159683\n",
      "Scoring - median 60.99966049194336 68.22143173217773\n",
      "Scoring - min 30.000062942504883 44.96748352050781\n",
      "Scoring - max 99.99986267089844 89.81539916992188\n",
      "Scoring - mean 61.45395826339722 67.7157554244995\n",
      "Scoring - MSE:  72.27779 RMSE:  8.501634328461959\n",
      "Scoring - R2:  0.6247770996203931\n",
      "batch_idx 71 154\n",
      "batch_idx 72 154\n",
      "batch_idx 73 154\n",
      "batch_idx 74 154\n",
      "batch_idx 75 154\n",
      "Train Epoch: 2 [2400/4960 (48%)]\tLoss: 0.383311\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (37.9970)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.574483397822125\n",
      "Scoring - median 60.99966049194336 62.9825553894043\n",
      "Scoring - min 30.000062942504883 44.67632293701172\n",
      "Scoring - max 99.99986267089844 81.3119888305664\n",
      "Scoring - mean 61.45395826339722 62.61859220123291\n",
      "Scoring - MSE:  37.997032 RMSE:  6.164173275105701\n",
      "Scoring - R2:  0.5801569690056421\n",
      "batch_idx 76 154\n",
      "batch_idx 77 154\n",
      "batch_idx 78 154\n",
      "batch_idx 79 154\n",
      "batch_idx 80 154\n",
      "Train Epoch: 2 [2560/4960 (52%)]\tLoss: 0.637682\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (36.7416)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.834845863395126\n",
      "Scoring - median 60.99966049194336 62.410654067993164\n",
      "Scoring - min 30.000062942504883 40.872955322265625\n",
      "Scoring - max 99.99986267089844 84.01715087890625\n",
      "Scoring - mean 61.45395826339722 62.076132141113284\n",
      "Scoring - MSE:  36.741627 RMSE:  6.061487172262427\n",
      "Scoring - R2:  0.5861861577264125\n",
      "batch_idx 81 154\n",
      "batch_idx 82 154\n",
      "batch_idx 83 154\n",
      "batch_idx 84 154\n",
      "batch_idx 85 154\n",
      "Train Epoch: 2 [2720/4960 (55%)]\tLoss: 1.175339\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (34.4996)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.684683478689436\n",
      "Scoring - median 60.99966049194336 59.398990631103516\n",
      "Scoring - min 30.000062942504883 30.562536239624023\n",
      "Scoring - max 99.99986267089844 82.49693298339844\n",
      "Scoring - mean 61.45395826339722 60.13491386413574\n",
      "Scoring - MSE:  34.49965 RMSE:  5.873640187128554\n",
      "Scoring - R2:  0.6396420282518771\n",
      "batch_idx 86 154\n",
      "batch_idx 87 154\n",
      "batch_idx 88 154\n",
      "batch_idx 89 154\n",
      "batch_idx 90 154\n",
      "Train Epoch: 2 [2880/4960 (58%)]\tLoss: 0.496860\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (31.3338)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.885999046460981\n",
      "Scoring - median 60.99966049194336 59.604936599731445\n",
      "Scoring - min 30.000062942504883 36.730567932128906\n",
      "Scoring - max 99.99986267089844 80.20220947265625\n",
      "Scoring - mean 61.45395826339722 60.4153235168457\n",
      "Scoring - MSE:  31.333782 RMSE:  5.597658635183547\n",
      "Scoring - R2:  0.6523587476699191\n",
      "batch_idx 91 154\n",
      "batch_idx 92 154\n",
      "batch_idx 93 154\n",
      "batch_idx 94 154\n",
      "batch_idx 95 154\n",
      "Train Epoch: 2 [3040/4960 (61%)]\tLoss: 0.111854\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (28.1716)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.431579639835021\n",
      "Scoring - median 60.99966049194336 60.36169242858887\n",
      "Scoring - min 30.000062942504883 36.98057556152344\n",
      "Scoring - max 99.99986267089844 79.1086654663086\n",
      "Scoring - mean 61.45395826339722 60.910555854797366\n",
      "Scoring - MSE:  28.171564 RMSE:  5.307689148977439\n",
      "Scoring - R2:  0.6789041272867283\n",
      "batch_idx 96 154\n",
      "batch_idx 97 154\n",
      "batch_idx 98 154\n",
      "batch_idx 99 154\n",
      "batch_idx 100 154\n",
      "Train Epoch: 2 [3200/4960 (65%)]\tLoss: 0.241651\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (29.1062)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.364993477397661\n",
      "Scoring - median 60.99966049194336 59.87090873718262\n",
      "Scoring - min 30.000062942504883 36.025047302246094\n",
      "Scoring - max 99.99986267089844 87.42716979980469\n",
      "Scoring - mean 61.45395826339722 60.7703510055542\n",
      "Scoring - MSE:  29.106232 RMSE:  5.3950191556150315\n",
      "Scoring - R2:  0.675359454729779\n",
      "batch_idx 101 154\n",
      "batch_idx 102 154\n",
      "batch_idx 103 154\n",
      "batch_idx 104 154\n",
      "batch_idx 105 154\n",
      "Train Epoch: 2 [3360/4960 (68%)]\tLoss: 0.434223\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (26.7568)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.441926136897198\n",
      "Scoring - median 60.99966049194336 61.51145553588867\n",
      "Scoring - min 30.000062942504883 36.755165100097656\n",
      "Scoring - max 99.99986267089844 83.87736511230469\n",
      "Scoring - mean 61.45395826339722 62.41823383331299\n",
      "Scoring - MSE:  26.75681 RMSE:  5.172698448065491\n",
      "Scoring - R2:  0.7063284843400078\n",
      "batch_idx 106 154\n",
      "batch_idx 107 154\n",
      "batch_idx 108 154\n",
      "batch_idx 109 154\n",
      "batch_idx 110 154\n",
      "Train Epoch: 2 [3520/4960 (71%)]\tLoss: 0.452791\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (82.3042)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.126225147698879\n",
      "Scoring - median 60.99966049194336 54.1840877532959\n",
      "Scoring - min 30.000062942504883 29.18248748779297\n",
      "Scoring - max 99.99986267089844 73.84881591796875\n",
      "Scoring - mean 61.45395826339722 54.68481529998779\n",
      "Scoring - MSE:  82.304184 RMSE:  9.072165340201915\n",
      "Scoring - R2:  0.5789356596199398\n",
      "batch_idx 111 154\n",
      "batch_idx 112 154\n",
      "batch_idx 113 154\n",
      "batch_idx 114 154\n",
      "batch_idx 115 154\n",
      "Train Epoch: 2 [3680/4960 (74%)]\tLoss: 1.043359\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (34.6714)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 5.34814248558494\n",
      "Scoring - median 60.99966049194336 60.446908950805664\n",
      "Scoring - min 30.000062942504883 46.383270263671875\n",
      "Scoring - max 99.99986267089844 74.69358825683594\n",
      "Scoring - mean 61.45395826339722 60.52098069000244\n",
      "Scoring - MSE:  34.6714 RMSE:  5.888242366177007\n",
      "Scoring - R2:  0.6691266634266164\n",
      "batch_idx 116 154\n",
      "batch_idx 117 154\n",
      "batch_idx 118 154\n",
      "batch_idx 119 154\n",
      "batch_idx 120 154\n",
      "Train Epoch: 2 [3840/4960 (77%)]\tLoss: 0.483191\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (32.7529)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.383112867386426\n",
      "Scoring - median 60.99966049194336 60.27402114868164\n",
      "Scoring - min 30.000062942504883 31.823833465576172\n",
      "Scoring - max 99.99986267089844 86.30301666259766\n",
      "Scoring - mean 61.45395826339722 61.38833532714844\n",
      "Scoring - MSE:  32.75289 RMSE:  5.723014200622548\n",
      "Scoring - R2:  0.6602399555941167\n",
      "batch_idx 121 154\n",
      "batch_idx 122 154\n",
      "batch_idx 123 154\n",
      "batch_idx 124 154\n",
      "batch_idx 125 154\n",
      "Train Epoch: 2 [4000/4960 (81%)]\tLoss: 0.167239\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (31.9090)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.59666813390951\n",
      "Scoring - median 60.99966049194336 60.22169494628906\n",
      "Scoring - min 30.000062942504883 38.76451110839844\n",
      "Scoring - max 99.99986267089844 89.15664672851562\n",
      "Scoring - mean 61.45395826339722 61.87803330993653\n",
      "Scoring - MSE:  31.909 RMSE:  5.648805218515551\n",
      "Scoring - R2:  0.6771046658843368\n",
      "batch_idx 126 154\n",
      "batch_idx 127 154\n",
      "batch_idx 128 154\n",
      "batch_idx 129 154\n",
      "batch_idx 130 154\n",
      "Train Epoch: 2 [4160/4960 (84%)]\tLoss: 0.182087\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (27.3570)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.483618263898041\n",
      "Scoring - median 60.99966049194336 61.422983169555664\n",
      "Scoring - min 30.000062942504883 45.1956787109375\n",
      "Scoring - max 99.99986267089844 84.36117553710938\n",
      "Scoring - mean 61.45395826339722 62.49274263763428\n",
      "Scoring - MSE:  27.357 RMSE:  5.230391988269345\n",
      "Scoring - R2:  0.6976776391589266\n",
      "batch_idx 131 154\n",
      "batch_idx 132 154\n",
      "batch_idx 133 154\n",
      "batch_idx 134 154\n",
      "batch_idx 135 154\n",
      "Train Epoch: 2 [4320/4960 (87%)]\tLoss: 0.098198\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (28.7802)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.29653946014303\n",
      "Scoring - median 60.99966049194336 62.121829986572266\n",
      "Scoring - min 30.000062942504883 43.96779251098633\n",
      "Scoring - max 99.99986267089844 86.08937072753906\n",
      "Scoring - mean 61.45395826339722 63.29103781890869\n",
      "Scoring - MSE:  28.78022 RMSE:  5.3647199397301515\n",
      "Scoring - R2:  0.709190674021372\n",
      "batch_idx 136 154\n",
      "batch_idx 137 154\n",
      "batch_idx 138 154\n",
      "batch_idx 139 154\n",
      "batch_idx 140 154\n",
      "Train Epoch: 2 [4480/4960 (90%)]\tLoss: 0.157892\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (24.8893)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.857308664351087\n",
      "Scoring - median 60.99966049194336 60.668596267700195\n",
      "Scoring - min 30.000062942504883 39.924415588378906\n",
      "Scoring - max 99.99986267089844 82.66412353515625\n",
      "Scoring - mean 61.45395826339722 61.553535331726074\n",
      "Scoring - MSE:  24.889297 RMSE:  4.988917466279791\n",
      "Scoring - R2:  0.7128414584424568\n",
      "batch_idx 141 154\n",
      "batch_idx 142 154\n",
      "batch_idx 143 154\n",
      "batch_idx 144 154\n",
      "batch_idx 145 154\n",
      "Train Epoch: 2 [4640/4960 (94%)]\tLoss: 0.901522\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (73.0181)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.047768473644936\n",
      "Scoring - median 60.99966049194336 54.982431411743164\n",
      "Scoring - min 30.000062942504883 28.01976776123047\n",
      "Scoring - max 99.99986267089844 73.9683837890625\n",
      "Scoring - mean 61.45395826339722 55.18648163604736\n",
      "Scoring - MSE:  73.01813 RMSE:  8.54506450773815\n",
      "Scoring - R2:  0.6112149610995699\n",
      "batch_idx 146 154\n",
      "batch_idx 147 154\n",
      "batch_idx 148 154\n",
      "batch_idx 149 154\n",
      "batch_idx 150 154\n",
      "Train Epoch: 2 [4800/4960 (97%)]\tLoss: 0.464564\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (32.8161)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.0012185282821635\n",
      "Scoring - median 60.99966049194336 62.63616180419922\n",
      "Scoring - min 30.000062942504883 41.61424255371094\n",
      "Scoring - max 99.99986267089844 80.29019165039062\n",
      "Scoring - mean 61.45395826339722 62.43803359222412\n",
      "Scoring - MSE:  32.816063 RMSE:  5.72853060803956\n",
      "Scoring - R2:  0.6343767538342895\n",
      "batch_idx 151 154\n",
      "batch_idx 152 154\n",
      "batch_idx 153 154\n",
      "batch_idx 154 154\n",
      "\n",
      "Test set: Loss: avg MSE (36.4417)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.346398830099076\n",
      "Scoring - median 60.99966049194336 62.23197555541992\n",
      "Scoring - min 30.000062942504883 27.625064849853516\n",
      "Scoring - max 99.99986267089844 86.56820678710938\n",
      "Scoring - mean 61.45395826339722 62.764118225097654\n",
      "Scoring - MSE:  36.441715 RMSE:  6.036697378573694\n",
      "Scoring - R2:  0.6406897796054745\n",
      "batch_idx 0 154\n",
      "Train Epoch: 3 [0/4960 (0%)]\tLoss: 0.327218\tTime: 0.012s\n",
      "\n",
      "Test set: Loss: avg MSE (40.3932)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.78916681984476\n",
      "Scoring - median 60.99966049194336 63.114572525024414\n",
      "Scoring - min 30.000062942504883 30.966909408569336\n",
      "Scoring - max 99.99986267089844 90.02509307861328\n",
      "Scoring - mean 61.45395826339722 63.21710596084595\n",
      "Scoring - MSE:  40.393185 RMSE:  6.35556328438835\n",
      "Scoring - R2:  0.6346923694353244\n",
      "\n",
      "Test set: Loss: avg MSE (40.3932)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.78916681984476\n",
      "Scoring - median 60.99966049194336 63.114572525024414\n",
      "Scoring - min 30.000062942504883 30.966909408569336\n",
      "Scoring - max 99.99986267089844 90.02509307861328\n",
      "Scoring - mean 61.45395826339722 63.21710596084595\n",
      "Scoring - MSE:  40.393185 RMSE:  6.35556328438835\n",
      "Scoring - R2:  0.6346923694353244\n",
      "batch_idx 1 154\n",
      "batch_idx 2 154\n",
      "batch_idx 3 154\n",
      "batch_idx 4 154\n",
      "batch_idx 5 154\n",
      "Train Epoch: 3 [160/4960 (3%)]\tLoss: 0.313326\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (31.1014)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.250336573504274\n",
      "Scoring - median 60.99966049194336 61.711265563964844\n",
      "Scoring - min 30.000062942504883 31.82632064819336\n",
      "Scoring - max 99.99986267089844 83.80003356933594\n",
      "Scoring - mean 61.45395826339722 62.537160217285155\n",
      "Scoring - MSE:  31.101381 RMSE:  5.576861241045888\n",
      "Scoring - R2:  0.6600364829377896\n",
      "batch_idx 6 154\n",
      "batch_idx 7 154\n",
      "batch_idx 8 154\n",
      "batch_idx 9 154\n",
      "batch_idx 10 154\n",
      "Train Epoch: 3 [320/4960 (6%)]\tLoss: 0.289154\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (30.6830)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.126338754242533\n",
      "Scoring - median 60.99966049194336 62.048789978027344\n",
      "Scoring - min 30.000062942504883 36.40318298339844\n",
      "Scoring - max 99.99986267089844 79.56065368652344\n",
      "Scoring - mean 61.45395826339722 62.209689918518066\n",
      "Scoring - MSE:  30.683043 RMSE:  5.5392276109801735\n",
      "Scoring - R2:  0.6543215739011323\n",
      "batch_idx 11 154\n",
      "batch_idx 12 154\n",
      "batch_idx 13 154\n",
      "batch_idx 14 154\n",
      "batch_idx 15 154\n",
      "Train Epoch: 3 [480/4960 (10%)]\tLoss: 0.407637\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (32.1298)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.516924936939985\n",
      "Scoring - median 60.99966049194336 62.415788650512695\n",
      "Scoring - min 30.000062942504883 31.96598243713379\n",
      "Scoring - max 99.99986267089844 87.7642822265625\n",
      "Scoring - mean 61.45395826339722 62.73226176834106\n",
      "Scoring - MSE:  32.12985 RMSE:  5.668319722830092\n",
      "Scoring - R2:  0.6857779868278888\n",
      "batch_idx 16 154\n",
      "batch_idx 17 154\n",
      "batch_idx 18 154\n",
      "batch_idx 19 154\n",
      "batch_idx 20 154\n",
      "Train Epoch: 3 [640/4960 (13%)]\tLoss: 0.268857\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (24.1306)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.737296857925315\n",
      "Scoring - median 60.99966049194336 61.27563285827637\n",
      "Scoring - min 30.000062942504883 36.53192901611328\n",
      "Scoring - max 99.99986267089844 84.91552734375\n",
      "Scoring - mean 61.45395826339722 61.896924446105956\n",
      "Scoring - MSE:  24.130621 RMSE:  4.912292841069321\n",
      "Scoring - R2:  0.7307754354600471\n",
      "batch_idx 21 154\n",
      "batch_idx 22 154\n",
      "batch_idx 23 154\n",
      "batch_idx 24 154\n",
      "batch_idx 25 154\n",
      "Train Epoch: 3 [800/4960 (16%)]\tLoss: 0.601522\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (27.1762)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.907226553029563\n",
      "Scoring - median 60.99966049194336 62.63640785217285\n",
      "Scoring - min 30.000062942504883 38.87112045288086\n",
      "Scoring - max 99.99986267089844 86.26643371582031\n",
      "Scoring - mean 61.45395826339722 63.36186498260498\n",
      "Scoring - MSE:  27.176157 RMSE:  5.213075579509725\n",
      "Scoring - R2:  0.7379321598191388\n",
      "batch_idx 26 154\n",
      "batch_idx 27 154\n",
      "batch_idx 28 154\n",
      "batch_idx 29 154\n",
      "batch_idx 30 154\n",
      "Train Epoch: 3 [960/4960 (19%)]\tLoss: 0.304444\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (22.7526)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.402430154158859\n",
      "Scoring - median 60.99966049194336 59.868568420410156\n",
      "Scoring - min 30.000062942504883 41.91627502441406\n",
      "Scoring - max 99.99986267089844 81.67216491699219\n",
      "Scoring - mean 61.45395826339722 60.96092047119141\n",
      "Scoring - MSE:  22.752554 RMSE:  4.769963725210008\n",
      "Scoring - R2:  0.7447833130799169\n",
      "batch_idx 31 154\n",
      "batch_idx 32 154\n",
      "batch_idx 33 154\n",
      "batch_idx 34 154\n",
      "batch_idx 35 154\n",
      "Train Epoch: 3 [1120/4960 (23%)]\tLoss: 0.217923\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (24.8130)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.471851469066209\n",
      "Scoring - median 60.99966049194336 62.48685073852539\n",
      "Scoring - min 30.000062942504883 41.43974304199219\n",
      "Scoring - max 99.99986267089844 87.24934387207031\n",
      "Scoring - mean 61.45395826339722 63.5636936340332\n",
      "Scoring - MSE:  24.812954 RMSE:  4.98126027717631\n",
      "Scoring - R2:  0.7661952007608571\n",
      "batch_idx 36 154\n",
      "batch_idx 37 154\n",
      "batch_idx 38 154\n",
      "batch_idx 39 154\n",
      "batch_idx 40 154\n",
      "Train Epoch: 3 [1280/4960 (26%)]\tLoss: 0.115818\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (24.1495)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.490012019120996\n",
      "Scoring - median 60.99966049194336 61.89436340332031\n",
      "Scoring - min 30.000062942504883 37.80217742919922\n",
      "Scoring - max 99.99986267089844 91.2674331665039\n",
      "Scoring - mean 61.45395826339722 62.98909700775147\n",
      "Scoring - MSE:  24.149548 RMSE:  4.91421891829254\n",
      "Scoring - R2:  0.7688337980407514\n",
      "batch_idx 41 154\n",
      "batch_idx 42 154\n",
      "batch_idx 43 154\n",
      "batch_idx 44 154\n",
      "batch_idx 45 154\n",
      "Train Epoch: 3 [1440/4960 (29%)]\tLoss: 0.243579\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (20.9697)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.71881709096064\n",
      "Scoring - median 60.99966049194336 60.74310302734375\n",
      "Scoring - min 30.000062942504883 41.7760009765625\n",
      "Scoring - max 99.99986267089844 84.31930541992188\n",
      "Scoring - mean 61.45395826339722 61.51657871246338\n",
      "Scoring - MSE:  20.969738 RMSE:  4.579272650388028\n",
      "Scoring - R2:  0.7598104131463759\n",
      "batch_idx 46 154\n",
      "batch_idx 47 154\n",
      "batch_idx 48 154\n",
      "batch_idx 49 154\n",
      "batch_idx 50 154\n",
      "Train Epoch: 3 [1600/4960 (32%)]\tLoss: 0.136939\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (20.9455)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.540011565061217\n",
      "Scoring - median 60.99966049194336 60.679222106933594\n",
      "Scoring - min 30.000062942504883 41.84101104736328\n",
      "Scoring - max 99.99986267089844 81.93023681640625\n",
      "Scoring - mean 61.45395826339722 60.86576103973389\n",
      "Scoring - MSE:  20.945457 RMSE:  4.576620746631306\n",
      "Scoring - R2:  0.7665254488564663\n",
      "batch_idx 51 154\n",
      "batch_idx 52 154\n",
      "batch_idx 53 154\n",
      "batch_idx 54 154\n",
      "batch_idx 55 154\n",
      "Train Epoch: 3 [1760/4960 (35%)]\tLoss: 0.047526\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (21.2918)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.194762502036198\n",
      "Scoring - median 60.99966049194336 60.90624809265137\n",
      "Scoring - min 30.000062942504883 37.99507522583008\n",
      "Scoring - max 99.99986267089844 87.47650909423828\n",
      "Scoring - mean 61.45395826339722 61.2348812789917\n",
      "Scoring - MSE:  21.291811 RMSE:  4.614305038614145\n",
      "Scoring - R2:  0.7673164844019977\n",
      "batch_idx 56 154\n",
      "batch_idx 57 154\n",
      "batch_idx 58 154\n",
      "batch_idx 59 154\n",
      "batch_idx 60 154\n",
      "Train Epoch: 3 [1920/4960 (39%)]\tLoss: 0.102769\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (19.5766)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.175399783599882\n",
      "Scoring - median 60.99966049194336 61.13828086853027\n",
      "Scoring - min 30.000062942504883 40.68977355957031\n",
      "Scoring - max 99.99986267089844 84.5123062133789\n",
      "Scoring - mean 61.45395826339722 61.736740615844724\n",
      "Scoring - MSE:  19.576574 RMSE:  4.4245422729997195\n",
      "Scoring - R2:  0.7749736056682415\n",
      "batch_idx 61 154\n",
      "batch_idx 62 154\n",
      "batch_idx 63 154\n",
      "batch_idx 64 154\n",
      "batch_idx 65 154\n",
      "Train Epoch: 3 [2080/4960 (42%)]\tLoss: 0.165539\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (22.0413)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.695378309932808\n",
      "Scoring - median 60.99966049194336 61.54806327819824\n",
      "Scoring - min 30.000062942504883 43.71958923339844\n",
      "Scoring - max 99.99986267089844 85.33255004882812\n",
      "Scoring - mean 61.45395826339722 62.56819113922119\n",
      "Scoring - MSE:  22.041313 RMSE:  4.694817693093814\n",
      "Scoring - R2:  0.7620642911063877\n",
      "batch_idx 66 154\n",
      "batch_idx 67 154\n",
      "batch_idx 68 154\n",
      "batch_idx 69 154\n",
      "batch_idx 70 154\n",
      "Train Epoch: 3 [2240/4960 (45%)]\tLoss: 0.536824\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (26.7723)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.522901677354959\n",
      "Scoring - median 60.99966049194336 63.2978401184082\n",
      "Scoring - min 30.000062942504883 41.23101806640625\n",
      "Scoring - max 99.99986267089844 87.9295883178711\n",
      "Scoring - mean 61.45395826339722 64.11275723266601\n",
      "Scoring - MSE:  26.772345 RMSE:  5.174199898460959\n",
      "Scoring - R2:  0.7738778756169092\n",
      "batch_idx 71 154\n",
      "batch_idx 72 154\n",
      "batch_idx 73 154\n",
      "batch_idx 74 154\n",
      "batch_idx 75 154\n",
      "Train Epoch: 3 [2400/4960 (48%)]\tLoss: 0.127481\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (24.2222)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.839842115666212\n",
      "Scoring - median 60.99966049194336 60.80172538757324\n",
      "Scoring - min 30.000062942504883 33.81962585449219\n",
      "Scoring - max 99.99986267089844 91.63272094726562\n",
      "Scoring - mean 61.45395826339722 61.558701530456545\n",
      "Scoring - MSE:  24.222235 RMSE:  4.921608957033477\n",
      "Scoring - R2:  0.7558068770838832\n",
      "batch_idx 76 154\n",
      "batch_idx 77 154\n",
      "batch_idx 78 154\n",
      "batch_idx 79 154\n",
      "batch_idx 80 154\n",
      "Train Epoch: 3 [2560/4960 (52%)]\tLoss: 0.362982\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (22.3412)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.92505853886958\n",
      "Scoring - median 60.99966049194336 61.92928886413574\n",
      "Scoring - min 30.000062942504883 38.863040924072266\n",
      "Scoring - max 99.99986267089844 90.39633178710938\n",
      "Scoring - mean 61.45395826339722 62.843123878479005\n",
      "Scoring - MSE:  22.34119 RMSE:  4.726646838736184\n",
      "Scoring - R2:  0.7709427488379851\n",
      "batch_idx 81 154\n",
      "batch_idx 82 154\n",
      "batch_idx 83 154\n",
      "batch_idx 84 154\n",
      "batch_idx 85 154\n",
      "Train Epoch: 3 [2720/4960 (55%)]\tLoss: 0.866082\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (21.6847)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.399703789549617\n",
      "Scoring - median 60.99966049194336 61.63943862915039\n",
      "Scoring - min 30.000062942504883 37.891395568847656\n",
      "Scoring - max 99.99986267089844 87.09725952148438\n",
      "Scoring - mean 61.45395826339722 62.36641429138184\n",
      "Scoring - MSE:  21.684704 RMSE:  4.656683779998842\n",
      "Scoring - R2:  0.7602536150571992\n",
      "batch_idx 86 154\n",
      "batch_idx 87 154\n",
      "batch_idx 88 154\n",
      "batch_idx 89 154\n",
      "batch_idx 90 154\n",
      "Train Epoch: 3 [2880/4960 (58%)]\tLoss: 0.229723\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (21.3794)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.677494216229618\n",
      "Scoring - median 60.99966049194336 61.93891143798828\n",
      "Scoring - min 30.000062942504883 37.67133331298828\n",
      "Scoring - max 99.99986267089844 90.53556823730469\n",
      "Scoring - mean 61.45395826339722 62.55452000427246\n",
      "Scoring - MSE:  21.379446 RMSE:  4.6237913047263595\n",
      "Scoring - R2:  0.7702038770643725\n",
      "batch_idx 91 154\n",
      "batch_idx 92 154\n",
      "batch_idx 93 154\n",
      "batch_idx 94 154\n",
      "batch_idx 95 154\n",
      "Train Epoch: 3 [3040/4960 (61%)]\tLoss: 0.225266\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (20.2919)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.474488519103486\n",
      "Scoring - median 60.99966049194336 61.227691650390625\n",
      "Scoring - min 30.000062942504883 37.031768798828125\n",
      "Scoring - max 99.99986267089844 88.41773986816406\n",
      "Scoring - mean 61.45395826339722 61.55588154602051\n",
      "Scoring - MSE:  20.291864 RMSE:  4.504649197789058\n",
      "Scoring - R2:  0.7671077390764581\n",
      "batch_idx 96 154\n",
      "batch_idx 97 154\n",
      "batch_idx 98 154\n",
      "batch_idx 99 154\n",
      "batch_idx 100 154\n",
      "Train Epoch: 3 [3200/4960 (65%)]\tLoss: 0.162246\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (24.6966)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.02861342834236\n",
      "Scoring - median 60.99966049194336 60.68044853210449\n",
      "Scoring - min 30.000062942504883 36.96817398071289\n",
      "Scoring - max 99.99986267089844 87.69510650634766\n",
      "Scoring - mean 61.45395826339722 61.094449043273926\n",
      "Scoring - MSE:  24.696648 RMSE:  4.969572179176289\n",
      "Scoring - R2:  0.7166972216988406\n",
      "batch_idx 101 154\n",
      "batch_idx 102 154\n",
      "batch_idx 103 154\n",
      "batch_idx 104 154\n",
      "batch_idx 105 154\n",
      "Train Epoch: 3 [3360/4960 (68%)]\tLoss: 0.304038\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (19.9982)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.750594100634832\n",
      "Scoring - median 60.99966049194336 61.36371612548828\n",
      "Scoring - min 30.000062942504883 34.23430633544922\n",
      "Scoring - max 99.99986267089844 92.02462005615234\n",
      "Scoring - mean 61.45395826339722 62.225384307861326\n",
      "Scoring - MSE:  19.99822 RMSE:  4.471936990133647\n",
      "Scoring - R2:  0.7793331730129837\n",
      "batch_idx 106 154\n",
      "batch_idx 107 154\n",
      "batch_idx 108 154\n",
      "batch_idx 109 154\n",
      "batch_idx 110 154\n",
      "Train Epoch: 3 [3520/4960 (71%)]\tLoss: 0.518957\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (74.9509)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.854930399916099\n",
      "Scoring - median 60.99966049194336 54.155147552490234\n",
      "Scoring - min 30.000062942504883 29.402450561523438\n",
      "Scoring - max 99.99986267089844 81.3589859008789\n",
      "Scoring - mean 61.45395826339722 54.735545475006106\n",
      "Scoring - MSE:  74.95089 RMSE:  8.657418182541626\n",
      "Scoring - R2:  0.6569989041702121\n",
      "batch_idx 111 154\n",
      "batch_idx 112 154\n",
      "batch_idx 113 154\n",
      "batch_idx 114 154\n",
      "batch_idx 115 154\n",
      "Train Epoch: 3 [3680/4960 (74%)]\tLoss: 1.021665\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (24.3903)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 6.124627537834467\n",
      "Scoring - median 60.99966049194336 61.16203308105469\n",
      "Scoring - min 30.000062942504883 45.53681182861328\n",
      "Scoring - max 99.99986267089844 80.73008728027344\n",
      "Scoring - mean 61.45395826339722 61.28133612060547\n",
      "Scoring - MSE:  24.390266 RMSE:  4.938650262820504\n",
      "Scoring - R2:  0.7660214860123852\n",
      "batch_idx 116 154\n",
      "batch_idx 117 154\n",
      "batch_idx 118 154\n",
      "batch_idx 119 154\n",
      "batch_idx 120 154\n",
      "Train Epoch: 3 [3840/4960 (77%)]\tLoss: 0.312919\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (22.8508)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.24635891380002\n",
      "Scoring - median 60.99966049194336 60.51631546020508\n",
      "Scoring - min 30.000062942504883 38.52104949951172\n",
      "Scoring - max 99.99986267089844 89.21461486816406\n",
      "Scoring - mean 61.45395826339722 61.09359355163574\n",
      "Scoring - MSE:  22.85084 RMSE:  4.7802551830282205\n",
      "Scoring - R2:  0.7534658568444174\n",
      "batch_idx 121 154\n",
      "batch_idx 122 154\n",
      "batch_idx 123 154\n",
      "batch_idx 124 154\n",
      "batch_idx 125 154\n",
      "Train Epoch: 3 [4000/4960 (81%)]\tLoss: 0.111318\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (22.0841)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.55602899413948\n",
      "Scoring - median 60.99966049194336 61.14688682556152\n",
      "Scoring - min 30.000062942504883 38.237937927246094\n",
      "Scoring - max 99.99986267089844 91.31423950195312\n",
      "Scoring - mean 61.45395826339722 62.05011441040039\n",
      "Scoring - MSE:  22.08409 RMSE:  4.699371157843867\n",
      "Scoring - R2:  0.7712406220235951\n",
      "batch_idx 126 154\n",
      "batch_idx 127 154\n",
      "batch_idx 128 154\n",
      "batch_idx 129 154\n",
      "batch_idx 130 154\n",
      "Train Epoch: 3 [4160/4960 (84%)]\tLoss: 0.130301\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (19.2837)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.8949525750710485\n",
      "Scoring - median 60.99966049194336 60.7193717956543\n",
      "Scoring - min 30.000062942504883 43.66796875\n",
      "Scoring - max 99.99986267089844 86.05349731445312\n",
      "Scoring - mean 61.45395826339722 61.86926987457275\n",
      "Scoring - MSE:  19.283665 RMSE:  4.391316966852784\n",
      "Scoring - R2:  0.7806691910458511\n",
      "batch_idx 131 154\n",
      "batch_idx 132 154\n",
      "batch_idx 133 154\n",
      "batch_idx 134 154\n",
      "batch_idx 135 154\n",
      "Train Epoch: 3 [4320/4960 (87%)]\tLoss: 0.102398\tTime: 0.007s\n",
      "\n",
      "Test set: Loss: avg MSE (19.1789)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.495859510879002\n",
      "Scoring - median 60.99966049194336 60.58233070373535\n",
      "Scoring - min 30.000062942504883 43.250343322753906\n",
      "Scoring - max 99.99986267089844 87.16358947753906\n",
      "Scoring - mean 61.45395826339722 61.993935661315916\n",
      "Scoring - MSE:  19.178875 RMSE:  4.379369243336582\n",
      "Scoring - R2:  0.7827857204211498\n",
      "batch_idx 136 154\n",
      "batch_idx 137 154\n",
      "batch_idx 138 154\n",
      "batch_idx 139 154\n",
      "batch_idx 140 154\n",
      "Train Epoch: 3 [4480/4960 (90%)]\tLoss: 0.115291\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (18.7880)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 8.110363887936893\n",
      "Scoring - median 60.99966049194336 60.11434364318848\n",
      "Scoring - min 30.000062942504883 42.57649612426758\n",
      "Scoring - max 99.99986267089844 85.13189697265625\n",
      "Scoring - mean 61.45395826339722 61.169845626831055\n",
      "Scoring - MSE:  18.78802 RMSE:  4.334514872543161\n",
      "Scoring - R2:  0.7842834135409441\n",
      "batch_idx 141 154\n",
      "batch_idx 142 154\n",
      "batch_idx 143 154\n",
      "batch_idx 144 154\n",
      "batch_idx 145 154\n",
      "Train Epoch: 3 [4640/4960 (94%)]\tLoss: 0.667211\tTime: 0.008s\n",
      "\n",
      "Test set: Loss: avg MSE (50.4599)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.830224576664605\n",
      "Scoring - median 60.99966049194336 55.728830337524414\n",
      "Scoring - min 30.000062942504883 33.60726547241211\n",
      "Scoring - max 99.99986267089844 79.66659545898438\n",
      "Scoring - mean 61.45395826339722 56.48086972808838\n",
      "Scoring - MSE:  50.459892 RMSE:  7.103512671414701\n",
      "Scoring - R2:  0.7030510169052964\n",
      "batch_idx 146 154\n",
      "batch_idx 147 154\n",
      "batch_idx 148 154\n",
      "batch_idx 149 154\n",
      "batch_idx 150 154\n",
      "Train Epoch: 3 [4800/4960 (97%)]\tLoss: 0.316690\tTime: 0.009s\n",
      "\n",
      "Test set: Loss: avg MSE (22.6449)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 7.779532880904552\n",
      "Scoring - median 60.99966049194336 61.55254554748535\n",
      "Scoring - min 30.000062942504883 44.486915588378906\n",
      "Scoring - max 99.99986267089844 84.328369140625\n",
      "Scoring - mean 61.45395826339722 62.105466743469236\n",
      "Scoring - MSE:  22.644913 RMSE:  4.75866711587673\n",
      "Scoring - R2:  0.7442554510955287\n",
      "batch_idx 151 154\n",
      "batch_idx 152 154\n",
      "batch_idx 153 154\n",
      "batch_idx 154 154\n",
      "\n",
      "Test set: Loss: avg MSE (27.5874)\tTime: 0.002s\n",
      "Scoring - std 9.308054141185021 9.251652809565325\n",
      "Scoring - median 60.99966049194336 62.10770797729492\n",
      "Scoring - min 30.000062942504883 41.947105407714844\n",
      "Scoring - max 99.99986267089844 90.73143768310547\n",
      "Scoring - mean 61.45395826339722 63.15095741271973\n",
      "Scoring - MSE:  27.587404 RMSE:  5.2523712979090345\n",
      "Scoring - R2:  0.7336972300644371\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "    # Save model\n",
    "    if not os.path.exists('{}/{}'.format(result_path, 'models')):\n",
    "        os.makedirs('{}/{}'.format(result_path, 'models'))\n",
    "\n",
    "    if epoch == 1:\n",
    "        save_model_to_txt(model, \"{}/models/\".format(result_path), epoch-1)\n",
    "    train(args, model, train_loader, optimizer, epoch, test_loader)\n",
    "    # test(args, model, test_loader, epoch, epoch * batches)\n",
    "    if epoch % args.log_interval == 0:\n",
    "        save_model(model, \"{}/models/ep{}.h5\".format(result_path, epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = \"from_fed_{}_{}_{}.csv\".format(args.federated_ratio, args.model_type, args.loss_type)\n",
    "csv_columns = ['mse_test', 'r_test']\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in result_array:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}